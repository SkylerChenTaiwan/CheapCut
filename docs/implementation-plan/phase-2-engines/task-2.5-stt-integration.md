# Task 2.5: Whisper STT æ•´åˆ

## ğŸ“‹ Task è³‡è¨Š

| é …ç›® | å…§å®¹ |
|------|------|
| **Task ID** | 2.5 |
| **Task åç¨±** | Whisper STT æ•´åˆ |
| **æ‰€å±¬ Phase** | Phase 2: Engines |
| **é ä¼°æ™‚é–“** | 3-4 å°æ™‚ (è¨­å®š 1h + å¯¦ä½œ 2h + æ¸¬è©¦ 1h) |
| **é›£åº¦** | â­â­ ä¸­ç­‰ |
| **å‰ç½® Task** | Task 2.1 (GCS å„²å­˜), Task 2.4 (å½±ç‰‡åˆ‡åˆ†) |

## ğŸ†˜ é‡åˆ°å•é¡Œæ€éº¼è¾¦?

### Step 1: å…ˆçœ‹éŒ¯èª¤è¨Šæ¯

**å¸¸è¦‹çš„ Whisper STT å•é¡Œ**:

1. **æ‰¾åˆ°éŒ¯èª¤çš„é—œéµå­—**
   ```
   Error: OpenAI API error: invalid_request_error
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  â† API è«‹æ±‚å•é¡Œ
   ```

2. **åˆ¤æ–·éŒ¯èª¤é¡å‹**
   - `invalid_api_key` â†’ API é‡‘é‘°ç„¡æ•ˆ
   - `file_too_large` â†’ éŸ³æª”è¶…é 25MB é™åˆ¶
   - `unsupported_format` â†’ éŸ³æª”æ ¼å¼ä¸æ”¯æ´
   - `invalid_language` â†’ èªè¨€ä»£ç¢¼éŒ¯èª¤
   - `rate_limit_exceeded` â†’ è¶…é API ä½¿ç”¨é™åˆ¶
   - `insufficient_quota` â†’ é¡åº¦ä¸è¶³

---

### Step 2: ä¸Šç¶²æœå°‹

#### ğŸ” æœå°‹æŠ€å·§

**âŒ ä¸å¥½çš„æœå°‹æ–¹å¼**:
```
"èªéŸ³è¾¨è­˜å¤±æ•—"  â† å¤ªæ¨¡ç³Š
"å­—å¹•ç”ŸæˆéŒ¯èª¤" â† æ²’æœ‰å…·é«”è³‡è¨Š
```

**âœ… å¥½çš„æœå°‹æ–¹å¼**:
```
"OpenAI Whisper API file size limit"  â† åŒ…å«å…·é«”éŒ¯èª¤
"Whisper API timestamp format SRT" â† æ˜ç¢ºçš„æŠ€è¡“å•é¡Œ
"Node.js Whisper API transcription with timestamps" â† å…·é«”çš„æŠ€è¡“æ£§
```

#### ğŸŒ æ¨è–¦è³‡æº

**å„ªå…ˆé †åº 1: å®˜æ–¹æ–‡ä»¶** (æœ€æº–ç¢º)
- OpenAI Whisper API: https://platform.openai.com/docs/guides/speech-to-text
- Whisper API Reference: https://platform.openai.com/docs/api-reference/audio
- Supported Formats: https://platform.openai.com/docs/guides/speech-to-text/supported-formats

**å„ªå…ˆé †åº 2: å®˜æ–¹ç¯„ä¾‹**
- OpenAI Node.js SDK: https://github.com/openai/openai-node
- Whisper Examples: https://platform.openai.com/docs/guides/speech-to-text/quickstart

---

### Step 3: æª¢æŸ¥ç’°å¢ƒè¨­å®š

```bash
# æª¢æŸ¥ OpenAI API Key
echo $OPENAI_API_KEY

# æª¢æŸ¥éŸ³æª”æ ¼å¼
ffprobe input.mp3 -show_format -show_streams

# æª¢æŸ¥éŸ³æª”å¤§å°
ls -lh input.mp3

# æ¸¬è©¦ API é€£ç·š
curl https://api.openai.com/v1/audio/transcriptions \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: multipart/form-data" \
  -F file="@test.mp3" \
  -F model="whisper-1"
```

---

## ğŸ¯ åŠŸèƒ½æè¿°

æ•´åˆ OpenAI Whisper APIï¼Œå°‡å½±ç‰‡éŸ³è»Œè½‰æ›ç‚ºæ–‡å­—å­—å¹•ï¼Œæ”¯æ´å¤šèªè¨€è¾¨è­˜å’Œæ™‚é–“ç¢¼åŒæ­¥ã€‚

### ç‚ºä»€éº¼éœ€è¦é€™å€‹?

- ğŸ¯ **å•é¡Œ**: å½±ç‰‡éœ€è¦è‡ªå‹•ç”Ÿæˆå­—å¹•ï¼Œæ‰‹å‹•æ‰“å­—å¤ªæ…¢
- âœ… **è§£æ±º**: ä½¿ç”¨ OpenAI Whisper API è‡ªå‹•èªéŸ³è½‰æ–‡å­—
- ğŸ’¡ **æ¯”å–»**: å°±åƒæœ‰ä¸€å€‹å°ˆæ¥­é€Ÿè¨˜å“¡ï¼Œè‡ªå‹•æŠŠå½±ç‰‡çš„å°è©±å¯«æˆå­—å¹•

### å®Œæˆå¾Œä½ æœƒæœ‰:

- âœ… OpenAI Whisper API å·²è¨­å®š
- âœ… éŸ³è»Œæå–èˆ‡è½‰æ›åŠŸèƒ½
- âœ… èªéŸ³è¾¨è­˜èˆ‡è½‰éŒ„åŠŸèƒ½
- âœ… SRT/VTT å­—å¹•æ ¼å¼ç”Ÿæˆ
- âœ… å¤šèªè¨€æ”¯æ´
- âœ… æ™‚é–“ç¢¼ç²¾ç¢ºåŒæ­¥
- âœ… å­—å¹•è³‡æ–™åº«å„²å­˜

---

## ğŸ“š å‰ç½®çŸ¥è­˜

ä»¥ä¸‹æ˜¯é€™å€‹ Task æœƒç”¨åˆ°çš„æŠ€è¡“ã€‚å¦‚æœä½ ä¸ç†Ÿæ‚‰ä¹Ÿæ²’é—œä¿‚,åªè¦ç…§è‘—æ­¥é©Ÿåšå°±èƒ½å®Œæˆã€‚

### 1. OpenAI Whisper API

**æ˜¯ä»€éº¼**: OpenAI æä¾›çš„èªéŸ³è¾¨è­˜æœå‹™ï¼Œæº–ç¢ºåº¦é«˜ä¸”æ”¯æ´å¤šèªè¨€

**æ ¸å¿ƒç‰¹æ€§**:
- **é«˜æº–ç¢ºåº¦**: ä½¿ç”¨ Whisper æ¨¡å‹ï¼Œè­˜åˆ¥ç‡é” 95%+
- **å¤šèªè¨€æ”¯æ´**: æ”¯æ´ 99 ç¨®èªè¨€
- **è‡ªå‹•æ¨™é»**: è‡ªå‹•åŠ ä¸Šæ¨™é»ç¬¦è™Ÿ
- **æ™‚é–“æˆ³**: å¯é¸æ“‡æ˜¯å¦è¿”å›æ™‚é–“ç¢¼ (timestamp)
- **æª”æ¡ˆé™åˆ¶**: æœ€å¤§ 25MB

**API ç«¯é»**:
```
POST https://api.openai.com/v1/audio/transcriptions
POST https://api.openai.com/v1/audio/translations (ç¿»è­¯æˆè‹±æ–‡)
```

**æ”¯æ´æ ¼å¼**:
- mp3, mp4, mpeg, mpga, m4a, wav, webm

**å›å‚³æ ¼å¼é¸é …**:
- `json`: ç´”æ–‡å­—çµæœ
- `verbose_json`: åŒ…å«æ™‚é–“æˆ³çš„è©³ç´°çµæœ
- `srt`: ç›´æ¥è¼¸å‡º SRT å­—å¹•
- `vtt`: ç›´æ¥è¼¸å‡º WebVTT å­—å¹•
- `text`: ç´”æ–‡å­—

### 2. éŸ³è»Œæå– (Audio Extraction)

**ç‚ºä»€éº¼éœ€è¦**: Whisper API åªæ¥å—éŸ³æª”ï¼Œéœ€è¦å¾å½±ç‰‡ä¸­æå–éŸ³è»Œ

**ä½¿ç”¨ FFmpeg æå–**:
```bash
ffmpeg -i input.mp4 -vn -acodec libmp3lame -q:a 2 output.mp3

# åƒæ•¸èªªæ˜:
# -vn: ä¸è™•ç†è¦–è¨Š (video none)
# -acodec libmp3lame: ä½¿ç”¨ MP3 ç·¨ç¢¼
# -q:a 2: éŸ³è³ªç­‰ç´š (0-9, è¶Šå°è¶Šå¥½)
```

**æª”æ¡ˆå¤§å°æ§åˆ¶**:
```bash
# å¦‚æœåŸå§‹éŸ³æª”è¶…é 25MBï¼Œé™ä½ä½å…ƒç‡
ffmpeg -i input.mp4 -vn -acodec libmp3lame -b:a 64k output.mp3

# æˆ–åˆ‡åˆ†æˆå¤šæ®µ
ffmpeg -i input.mp4 -vn -f segment -segment_time 600 -acodec libmp3lame output_%03d.mp3
```

### 3. å­—å¹•æ ¼å¼

**SRT æ ¼å¼** (SubRip):
```srt
1
00:00:00,000 --> 00:00:04,000
å¤§å®¶å¥½ï¼Œæ­¡è¿ä¾†åˆ°æˆ‘çš„é »é“

2
00:00:04,500 --> 00:00:08,000
ä»Šå¤©è¦ä»‹ç´¹å¦‚ä½•ä½¿ç”¨ AI ç”Ÿæˆå½±ç‰‡
```

**VTT æ ¼å¼** (WebVTT):
```vtt
WEBVTT

00:00:00.000 --> 00:00:04.000
å¤§å®¶å¥½ï¼Œæ­¡è¿ä¾†åˆ°æˆ‘çš„é »é“

00:00:04.500 --> 00:00:08.000
ä»Šå¤©è¦ä»‹ç´¹å¦‚ä½•ä½¿ç”¨ AI ç”Ÿæˆå½±ç‰‡
```

**æ ¼å¼å·®ç•°**:
- SRT: å‚³çµ±å­—å¹•æ ¼å¼ï¼Œå…¼å®¹æ€§å¥½
- VTT: Web æ¨™æº–ï¼Œæ”¯æ´æ¨£å¼è¨­å®š
- æ™‚é–“æ ¼å¼ä¸åŒ: SRT ç”¨é€—è™Ÿ (,)ï¼ŒVTT ç”¨å¥é» (.)

### 4. Whisper API å›å‚³æ ¼å¼

**Verbose JSON æ ¼å¼** (`response_format: "verbose_json"`):
```json
{
  "task": "transcribe",
  "language": "zh",
  "duration": 8.5,
  "text": "å¤§å®¶å¥½ï¼Œæ­¡è¿ä¾†åˆ°æˆ‘çš„é »é“ã€‚ä»Šå¤©è¦ä»‹ç´¹å¦‚ä½•ä½¿ç”¨ AI ç”Ÿæˆå½±ç‰‡ã€‚",
  "segments": [
    {
      "id": 0,
      "seek": 0,
      "start": 0.0,
      "end": 4.0,
      "text": "å¤§å®¶å¥½ï¼Œæ­¡è¿ä¾†åˆ°æˆ‘çš„é »é“ã€‚",
      "tokens": [50364, 1415, ...],
      "temperature": 0.0,
      "avg_logprob": -0.3,
      "compression_ratio": 1.2,
      "no_speech_prob": 0.01
    },
    {
      "id": 1,
      "seek": 0,
      "start": 4.5,
      "end": 8.0,
      "text": "ä»Šå¤©è¦ä»‹ç´¹å¦‚ä½•ä½¿ç”¨ AI ç”Ÿæˆå½±ç‰‡ã€‚",
      "tokens": [50614, 2589, ...],
      "temperature": 0.0,
      "avg_logprob": -0.25,
      "compression_ratio": 1.15,
      "no_speech_prob": 0.02
    }
  ]
}
```

**é‡è¦æ¬„ä½èªªæ˜**:
- `language`: è¾¨è­˜å‡ºçš„èªè¨€ä»£ç¢¼ (ISO 639-1)
- `duration`: éŸ³æª”ç¸½é•·åº¦ (ç§’)
- `segments`: åˆ†æ®µçµæœé™£åˆ—
- `start/end`: æ™‚é–“æˆ³ (ç§’ï¼Œæµ®é»æ•¸)
- `text`: è©²æ®µæ–‡å­—
- `no_speech_prob`: ç„¡èªéŸ³æ©Ÿç‡ (å¯ç”¨ä¾†éæ¿¾é›œéŸ³)

### 5. å¤šèªè¨€æ”¯æ´

**èªè¨€ä»£ç¢¼** (ISO 639-1):
```typescript
const SUPPORTED_LANGUAGES = {
  'zh': 'ä¸­æ–‡',
  'en': 'English',
  'ja': 'æ—¥æœ¬èª',
  'ko': 'í•œêµ­ì–´',
  'es': 'EspaÃ±ol',
  'fr': 'FranÃ§ais',
  'de': 'Deutsch',
  // ... æ”¯æ´ 99 ç¨®èªè¨€
};
```

**è‡ªå‹•æª¢æ¸¬èªè¨€**:
```typescript
// ä¸æŒ‡å®š languageï¼ŒWhisper æœƒè‡ªå‹•åµæ¸¬
const response = await openai.audio.transcriptions.create({
  file: audioFile,
  model: 'whisper-1',
  // ä¸è¨­å®š language åƒæ•¸
});

console.log(response.language); // å›å‚³åµæ¸¬åˆ°çš„èªè¨€
```

**æŒ‡å®šèªè¨€** (æé«˜æº–ç¢ºåº¦):
```typescript
const response = await openai.audio.transcriptions.create({
  file: audioFile,
  model: 'whisper-1',
  language: 'zh', // æŒ‡å®šç‚ºä¸­æ–‡
});
```

---

## ğŸ”— å‰ç½®ä¾è³´

### å¿…é ˆå…ˆå®Œæˆçš„ Task
- âœ… Task 2.1: GCS å„²å­˜å·²è¨­å®š (å„²å­˜éŸ³æª”)
- âœ… Task 2.4: å½±ç‰‡åˆ‡åˆ†å·²å¯¦ä½œ (æå–éŸ³è»Œ)

### ç³»çµ±éœ€æ±‚
- OpenAI API Key (éœ€è¦ä»˜è²»é¡åº¦)
- FFmpeg å·²å®‰è£
- Node.js >= 18
- è‡³å°‘ 500MB æš«å­˜ç©ºé–“ (è™•ç†éŸ³æª”)

### ç’°å¢ƒæª¢æŸ¥
```bash
# æª¢æŸ¥ FFmpeg
ffmpeg -version

# æª¢æŸ¥ OpenAI API Key
echo $OPENAI_API_KEY

# æª¢æŸ¥ API é¡åº¦
curl https://api.openai.com/v1/dashboard/billing/credit_grants \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

### å¥—ä»¶å®‰è£
```bash
cd backend
npm install openai formdata-node
npm install --save-dev @types/node
```

---

## ğŸ“ å¯¦ä½œæ­¥é©Ÿ

### æ­¥é©Ÿ 1: è¨­å®š OpenAI API

åœ¨ `backend/.env` åŠ å…¥:

```env
# OpenAI è¨­å®š
OPENAI_API_KEY=sk-...your-api-key...
WHISPER_MODEL=whisper-1
WHISPER_LANGUAGE=  # ç•™ç©ºç‚ºè‡ªå‹•åµæ¸¬

# å­—å¹•è¨­å®š
SUBTITLE_FORMAT=srt  # srt æˆ– vtt
SUBTITLE_MAX_LENGTH=42  # æ¯è¡Œæœ€å¤§å­—æ•¸
```

**å»ºç«‹è¨­å®šæª”** `backend/src/config/whisper.config.ts`:

```typescript
/**
 * Whisper STT è¨­å®š
 */

export const WHISPER_CONFIG = {
  // API è¨­å®š
  apiKey: process.env.OPENAI_API_KEY || '',
  model: process.env.WHISPER_MODEL || 'whisper-1',

  // èªè¨€è¨­å®š
  defaultLanguage: process.env.WHISPER_LANGUAGE || undefined, // undefined = è‡ªå‹•åµæ¸¬
  supportedLanguages: [
    'zh', 'en', 'ja', 'ko', 'es', 'fr', 'de', 'it', 'pt', 'ru'
  ],

  // æª”æ¡ˆé™åˆ¶
  maxFileSize: 25 * 1024 * 1024, // 25MB (Whisper API é™åˆ¶)
  supportedFormats: ['mp3', 'mp4', 'mpeg', 'mpga', 'm4a', 'wav', 'webm'],

  // å­—å¹•è¨­å®š
  subtitleFormat: (process.env.SUBTITLE_FORMAT || 'srt') as 'srt' | 'vtt',
  maxLineLength: parseInt(process.env.SUBTITLE_MAX_LENGTH || '42'),

  // éŸ³è³ªè¨­å®š
  audioBitrate: '64k', // é™ä½æª”æ¡ˆå¤§å°
  audioCodec: 'libmp3lame',

  // åˆ†æ®µè¨­å®š (è¶…é 25MB æ™‚è‡ªå‹•åˆ‡åˆ†)
  segmentDuration: 600, // 10 åˆ†é˜ä¸€æ®µ
} as const;
```

---

### æ­¥é©Ÿ 2: å»ºç«‹éŸ³è»Œæå–æœå‹™

å»ºç«‹ `backend/src/services/audio-extractor.service.ts`:

```typescript
/**
 * Audio Extractor Service
 *
 * å¾å½±ç‰‡ä¸­æå–éŸ³è»Œï¼Œä¸¦è½‰æ›ç‚º Whisper API å¯æ¥å—çš„æ ¼å¼
 */

import { exec } from 'child_process';
import { promisify } from 'util';
import { promises as fs } from 'fs';
import path from 'path';
import { WHISPER_CONFIG } from '../config/whisper.config';

const execAsync = promisify(exec);

/**
 * æª¢æŸ¥éŸ³æª”å¤§å°
 */
async function getFileSize(filePath: string): Promise<number> {
  const stats = await fs.stat(filePath);
  return stats.size;
}

/**
 * å¾å½±ç‰‡æå–éŸ³è»Œ
 *
 * @param videoPath - å½±ç‰‡æª”æ¡ˆè·¯å¾‘
 * @param outputPath - è¼¸å‡ºéŸ³æª”è·¯å¾‘
 * @returns éŸ³æª”è·¯å¾‘
 */
export async function extractAudio(
  videoPath: string,
  outputPath: string
): Promise<string> {
  // ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
  const outputDir = path.dirname(outputPath);
  await fs.mkdir(outputDir, { recursive: true });

  // ä½¿ç”¨ FFmpeg æå–éŸ³è»Œ
  const command = [
    'ffmpeg',
    '-i', `"${videoPath}"`,
    '-vn', // ä¸è™•ç†è¦–è¨Š
    '-acodec', WHISPER_CONFIG.audioCodec,
    '-b:a', WHISPER_CONFIG.audioBitrate,
    '-y', // è¦†è“‹å·²å­˜åœ¨æª”æ¡ˆ
    `"${outputPath}"`
  ].join(' ');

  await execAsync(command);

  // æª¢æŸ¥æª”æ¡ˆæ˜¯å¦æˆåŠŸå»ºç«‹
  const exists = await fs.access(outputPath).then(() => true).catch(() => false);
  if (!exists) {
    throw new Error('Failed to extract audio from video');
  }

  return outputPath;
}

/**
 * åˆ‡åˆ†éŸ³æª” (ç•¶æª”æ¡ˆè¶…é 25MB æ™‚)
 *
 * @param audioPath - åŸå§‹éŸ³æª”è·¯å¾‘
 * @param outputDir - è¼¸å‡ºç›®éŒ„
 * @returns åˆ‡åˆ†å¾Œçš„éŸ³æª”è·¯å¾‘é™£åˆ—
 */
export async function splitAudio(
  audioPath: string,
  outputDir: string
): Promise<string[]> {
  await fs.mkdir(outputDir, { recursive: true });

  const outputPattern = path.join(outputDir, 'segment_%03d.mp3');

  const command = [
    'ffmpeg',
    '-i', `"${audioPath}"`,
    '-f', 'segment',
    '-segment_time', WHISPER_CONFIG.segmentDuration.toString(),
    '-acodec', 'copy', // ä¸é‡æ–°ç·¨ç¢¼ï¼Œç›´æ¥åˆ‡åˆ†
    '-y',
    `"${outputPattern}"`
  ].join(' ');

  await execAsync(command);

  // åˆ—å‡ºæ‰€æœ‰åˆ‡åˆ†çš„æª”æ¡ˆ
  const files = await fs.readdir(outputDir);
  const segments = files
    .filter(f => f.startsWith('segment_') && f.endsWith('.mp3'))
    .map(f => path.join(outputDir, f))
    .sort();

  return segments;
}

/**
 * æº–å‚™éŸ³æª”çµ¦ Whisper API
 *
 * å¦‚æœæª”æ¡ˆè¶…é 25MBï¼Œè‡ªå‹•åˆ‡åˆ†
 *
 * @param videoPath - å½±ç‰‡è·¯å¾‘
 * @param workDir - å·¥ä½œç›®éŒ„
 * @returns æº–å‚™å¥½çš„éŸ³æª”è·¯å¾‘é™£åˆ—
 */
export async function prepareAudioForWhisper(
  videoPath: string,
  workDir: string
): Promise<string[]> {
  // æå–éŸ³è»Œ
  const audioPath = path.join(workDir, 'audio.mp3');
  await extractAudio(videoPath, audioPath);

  // æª¢æŸ¥æª”æ¡ˆå¤§å°
  const fileSize = await getFileSize(audioPath);

  if (fileSize <= WHISPER_CONFIG.maxFileSize) {
    // æª”æ¡ˆç¬¦åˆé™åˆ¶ï¼Œç›´æ¥ä½¿ç”¨
    return [audioPath];
  } else {
    // æª”æ¡ˆéå¤§ï¼Œéœ€è¦åˆ‡åˆ†
    console.log(`Audio file too large (${fileSize} bytes), splitting...`);
    const segmentsDir = path.join(workDir, 'segments');
    return await splitAudio(audioPath, segmentsDir);
  }
}

/**
 * æ¸…ç†æš«å­˜æª”æ¡ˆ
 */
export async function cleanupAudioFiles(workDir: string): Promise<void> {
  try {
    await fs.rm(workDir, { recursive: true, force: true });
  } catch (error) {
    console.error('Failed to cleanup audio files:', error);
  }
}
```

---

### æ­¥é©Ÿ 3: å»ºç«‹ Whisper STT æœå‹™

å»ºç«‹ `backend/src/services/whisper.service.ts`:

```typescript
/**
 * Whisper STT Service
 *
 * ä½¿ç”¨ OpenAI Whisper API é€²è¡ŒèªéŸ³è¾¨è­˜
 */

import OpenAI from 'openai';
import { createReadStream } from 'fs';
import { WHISPER_CONFIG } from '../config/whisper.config';

const openai = new OpenAI({
  apiKey: WHISPER_CONFIG.apiKey,
});

/**
 * Whisper API å›å‚³çš„ Segment
 */
export interface WhisperSegment {
  id: number;
  seek: number;
  start: number;
  end: number;
  text: string;
  tokens: number[];
  temperature: number;
  avg_logprob: number;
  compression_ratio: number;
  no_speech_prob: number;
}

/**
 * Whisper API å®Œæ•´å›å‚³
 */
export interface WhisperResponse {
  task: string;
  language: string;
  duration: number;
  text: string;
  segments: WhisperSegment[];
}

/**
 * è½‰éŒ„å–®ä¸€éŸ³æª”
 *
 * @param audioPath - éŸ³æª”è·¯å¾‘
 * @param language - èªè¨€ä»£ç¢¼ (å¯é¸ï¼Œä¸æŒ‡å®šå‰‡è‡ªå‹•åµæ¸¬)
 * @returns Whisper API å›å‚³çµæœ
 */
export async function transcribeAudio(
  audioPath: string,
  language?: string
): Promise<WhisperResponse> {
  const audioFile = createReadStream(audioPath);

  const response = await openai.audio.transcriptions.create({
    file: audioFile,
    model: WHISPER_CONFIG.model,
    response_format: 'verbose_json',
    language: language || WHISPER_CONFIG.defaultLanguage,
    timestamp_granularities: ['segment'],
  });

  return response as unknown as WhisperResponse;
}

/**
 * è½‰éŒ„å¤šæ®µéŸ³æª”ä¸¦åˆä½µçµæœ
 *
 * @param audioPaths - éŸ³æª”è·¯å¾‘é™£åˆ—
 * @param language - èªè¨€ä»£ç¢¼
 * @returns åˆä½µå¾Œçš„è½‰éŒ„çµæœ
 */
export async function transcribeMultipleAudios(
  audioPaths: string[],
  language?: string
): Promise<WhisperResponse> {
  const results: WhisperResponse[] = [];
  let totalDuration = 0;

  for (const audioPath of audioPaths) {
    const result = await transcribeAudio(audioPath, language);
    results.push(result);
    totalDuration += result.duration;
  }

  // åˆä½µæ‰€æœ‰ segmentsï¼Œä¸¦èª¿æ•´æ™‚é–“åç§»
  const allSegments: WhisperSegment[] = [];
  let timeOffset = 0;

  for (const result of results) {
    const adjustedSegments = result.segments.map(seg => ({
      ...seg,
      start: seg.start + timeOffset,
      end: seg.end + timeOffset,
    }));
    allSegments.push(...adjustedSegments);
    timeOffset += result.duration;
  }

  // é‡æ–°ç·¨è™Ÿ segment ID
  allSegments.forEach((seg, index) => {
    seg.id = index;
  });

  return {
    task: 'transcribe',
    language: results[0]?.language || 'unknown',
    duration: totalDuration,
    text: results.map(r => r.text).join(' '),
    segments: allSegments,
  };
}

/**
 * éæ¿¾æ‰ç„¡èªéŸ³ç‰‡æ®µ
 *
 * @param segments - åŸå§‹ segments
 * @param threshold - ç„¡èªéŸ³æ©Ÿç‡é–¾å€¼ (é è¨­ 0.5)
 * @returns éæ¿¾å¾Œçš„ segments
 */
export function filterSilentSegments(
  segments: WhisperSegment[],
  threshold: number = 0.5
): WhisperSegment[] {
  return segments.filter(seg => seg.no_speech_prob < threshold);
}
```

---

### æ­¥é©Ÿ 4: å»ºç«‹å­—å¹•æ ¼å¼è½‰æ›å™¨

å»ºç«‹ `backend/src/services/subtitle-formatter.service.ts`:

```typescript
/**
 * Subtitle Formatter Service
 *
 * å°‡ Whisper è½‰éŒ„çµæœè½‰æ›ç‚ºå­—å¹•æ ¼å¼ (SRT/VTT)
 */

import { WhisperSegment } from './whisper.service';
import { WHISPER_CONFIG } from '../config/whisper.config';

/**
 * å­—å¹•é …ç›®
 */
export interface SubtitleItem {
  index: number;
  startTime: number;
  endTime: number;
  text: string;
}

/**
 * æ ¼å¼åŒ–æ™‚é–“ç‚º SRT æ ¼å¼ (HH:MM:SS,mmm)
 */
function formatTimeSRT(seconds: number): string {
  const hours = Math.floor(seconds / 3600);
  const minutes = Math.floor((seconds % 3600) / 60);
  const secs = Math.floor(seconds % 60);
  const millis = Math.floor((seconds % 1) * 1000);

  return [
    hours.toString().padStart(2, '0'),
    minutes.toString().padStart(2, '0'),
    secs.toString().padStart(2, '0'),
  ].join(':') + ',' + millis.toString().padStart(3, '0');
}

/**
 * æ ¼å¼åŒ–æ™‚é–“ç‚º VTT æ ¼å¼ (HH:MM:SS.mmm)
 */
function formatTimeVTT(seconds: number): string {
  return formatTimeSRT(seconds).replace(',', '.');
}

/**
 * å°‡é•·æ–‡å­—åˆ‡åˆ†ç‚ºå¤šè¡Œ (é¿å…å–®è¡Œéé•·)
 */
function splitTextIntoLines(text: string, maxLength: number = WHISPER_CONFIG.maxLineLength): string[] {
  const words = text.split(' ');
  const lines: string[] = [];
  let currentLine = '';

  for (const word of words) {
    if ((currentLine + ' ' + word).length <= maxLength) {
      currentLine = currentLine ? currentLine + ' ' + word : word;
    } else {
      if (currentLine) lines.push(currentLine);
      currentLine = word;
    }
  }

  if (currentLine) lines.push(currentLine);

  return lines;
}

/**
 * å°‡ Whisper Segments è½‰æ›ç‚ºå­—å¹•é …ç›®
 */
export function segmentsToSubtitles(segments: WhisperSegment[]): SubtitleItem[] {
  return segments.map((seg, index) => ({
    index: index + 1,
    startTime: seg.start,
    endTime: seg.end,
    text: seg.text.trim(),
  }));
}

/**
 * ç”Ÿæˆ SRT å­—å¹•
 */
export function generateSRT(items: SubtitleItem[]): string {
  return items
    .map(item => {
      const lines = splitTextIntoLines(item.text);
      return [
        item.index.toString(),
        `${formatTimeSRT(item.startTime)} --> ${formatTimeSRT(item.endTime)}`,
        ...lines,
        '', // ç©ºè¡Œåˆ†éš”
      ].join('\n');
    })
    .join('\n');
}

/**
 * ç”Ÿæˆ VTT å­—å¹•
 */
export function generateVTT(items: SubtitleItem[]): string {
  const header = 'WEBVTT\n\n';
  const body = items
    .map(item => {
      const lines = splitTextIntoLines(item.text);
      return [
        `${formatTimeVTT(item.startTime)} --> ${formatTimeVTT(item.endTime)}`,
        ...lines,
        '', // ç©ºè¡Œåˆ†éš”
      ].join('\n');
    })
    .join('\n');

  return header + body;
}

/**
 * æ ¹æ“šè¨­å®šç”Ÿæˆå­—å¹•
 */
export function generateSubtitle(segments: WhisperSegment[]): string {
  const items = segmentsToSubtitles(segments);

  if (WHISPER_CONFIG.subtitleFormat === 'vtt') {
    return generateVTT(items);
  } else {
    return generateSRT(items);
  }
}

/**
 * å„²å­˜å­—å¹•åˆ°æª”æ¡ˆ
 */
export async function saveSubtitleFile(
  subtitle: string,
  filePath: string
): Promise<void> {
  const { promises: fs } = require('fs');
  await fs.writeFile(filePath, subtitle, 'utf-8');
}
```

---

### æ­¥é©Ÿ 5: å»ºç«‹è³‡æ–™è¡¨

åœ¨è³‡æ–™åº«åŸ·è¡Œ (`migrations/005_create_subtitles_table.sql`):

```sql
-- å­—å¹•ä¸»è¡¨
CREATE TABLE subtitles (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  video_id UUID NOT NULL REFERENCES videos(id) ON DELETE CASCADE,
  language VARCHAR(10) NOT NULL, -- ISO 639-1 èªè¨€ä»£ç¢¼
  format VARCHAR(10) NOT NULL, -- 'srt' æˆ– 'vtt'
  file_path VARCHAR(500), -- GCS æª”æ¡ˆè·¯å¾‘
  duration FLOAT, -- ç¸½æ™‚é•· (ç§’)
  word_count INTEGER, -- å­—æ•¸
  status VARCHAR(20) DEFAULT 'processing', -- 'processing', 'completed', 'failed'
  error_message TEXT,
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW()
);

-- å­—å¹•ç‰‡æ®µè¡¨
CREATE TABLE subtitle_segments (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  subtitle_id UUID NOT NULL REFERENCES subtitles(id) ON DELETE CASCADE,
  segment_index INTEGER NOT NULL,
  start_time FLOAT NOT NULL,
  end_time FLOAT NOT NULL,
  text TEXT NOT NULL,
  confidence FLOAT, -- ä¿¡å¿ƒåº¦ (å¾ Whisper avg_logprob è¨ˆç®—)
  no_speech_prob FLOAT, -- ç„¡èªéŸ³æ©Ÿç‡
  created_at TIMESTAMP DEFAULT NOW()
);

-- ç´¢å¼•
CREATE INDEX idx_subtitles_video ON subtitles(video_id);
CREATE INDEX idx_subtitles_language ON subtitles(language);
CREATE INDEX idx_subtitle_segments_subtitle ON subtitle_segments(subtitle_id);
CREATE INDEX idx_subtitle_segments_time ON subtitle_segments(start_time, end_time);

-- æ›´æ–°æ™‚é–“è§¸ç™¼å™¨
CREATE TRIGGER update_subtitles_updated_at
  BEFORE UPDATE ON subtitles
  FOR EACH ROW
  EXECUTE FUNCTION update_updated_at_column();
```

---

### æ­¥é©Ÿ 6: å»ºç«‹å­—å¹•å„²å­˜æœå‹™

å»ºç«‹ `backend/src/services/subtitle-storage.service.ts`:

```typescript
/**
 * Subtitle Storage Service
 *
 * å„²å­˜å­—å¹•åˆ°è³‡æ–™åº«å’Œ GCS
 */

import { db } from '../db';
import { WhisperResponse, WhisperSegment } from './whisper.service';
import * as storageService from './storage.service';
import { WHISPER_CONFIG } from '../config/whisper.config';

/**
 * å„²å­˜å­—å¹•åˆ°è³‡æ–™åº«
 */
export async function saveSubtitleToDatabase(
  videoId: string,
  whisperResponse: WhisperResponse,
  subtitleText: string,
  userId: string
): Promise<{ subtitleId: string; filePath: string }> {
  // ä¸Šå‚³å­—å¹•æª”æ¡ˆåˆ° GCS
  const filename = `subtitle_${videoId}.${WHISPER_CONFIG.subtitleFormat}`;
  const buffer = Buffer.from(subtitleText, 'utf-8');

  const { url: uploadUrl, filePath } = await storageService.generateUploadUrl(
    'subtitle' as any, // éœ€è¦åœ¨ storage.service.ts åŠ å…¥ 'subtitle' é¡å‹
    userId,
    filename,
    'text/plain'
  );

  // ä¸Šå‚³å­—å¹•å…§å®¹
  await fetch(uploadUrl, {
    method: 'PUT',
    headers: { 'Content-Type': 'text/plain' },
    body: buffer,
  });

  // æ’å…¥å­—å¹•ä¸»è¡¨
  const subtitleResult = await db.query(
    `INSERT INTO subtitles (
      video_id, language, format, file_path, duration, word_count, status
    ) VALUES ($1, $2, $3, $4, $5, $6, 'completed')
    RETURNING id`,
    [
      videoId,
      whisperResponse.language,
      WHISPER_CONFIG.subtitleFormat,
      filePath,
      whisperResponse.duration,
      whisperResponse.text.length,
    ]
  );

  const subtitleId = subtitleResult.rows[0].id;

  // æ’å…¥å­—å¹•ç‰‡æ®µ
  const segmentValues = whisperResponse.segments.map((seg, index) => [
    subtitleId,
    index,
    seg.start,
    seg.end,
    seg.text,
    Math.exp(seg.avg_logprob), // è½‰æ›ç‚º 0-1 çš„ä¿¡å¿ƒåº¦
    seg.no_speech_prob,
  ]);

  await db.query(
    `INSERT INTO subtitle_segments (
      subtitle_id, segment_index, start_time, end_time, text, confidence, no_speech_prob
    )
    SELECT * FROM UNNEST($1::uuid[], $2::int[], $3::float[], $4::float[], $5::text[], $6::float[], $7::float[])`,
    [
      segmentValues.map(v => v[0]),
      segmentValues.map(v => v[1]),
      segmentValues.map(v => v[2]),
      segmentValues.map(v => v[3]),
      segmentValues.map(v => v[4]),
      segmentValues.map(v => v[5]),
      segmentValues.map(v => v[6]),
    ]
  );

  return { subtitleId, filePath };
}

/**
 * æŸ¥è©¢å½±ç‰‡çš„å­—å¹•
 */
export async function getSubtitles(videoId: string) {
  const result = await db.query(
    `SELECT * FROM subtitles WHERE video_id = $1 ORDER BY created_at DESC`,
    [videoId]
  );

  return result.rows;
}

/**
 * æŸ¥è©¢å­—å¹•ç‰‡æ®µ
 */
export async function getSubtitleSegments(subtitleId: string) {
  const result = await db.query(
    `SELECT * FROM subtitle_segments
     WHERE subtitle_id = $1
     ORDER BY segment_index ASC`,
    [subtitleId]
  );

  return result.rows;
}

/**
 * æ›´æ–°å­—å¹•ç‹€æ…‹
 */
export async function updateSubtitleStatus(
  subtitleId: string,
  status: 'processing' | 'completed' | 'failed',
  errorMessage?: string
) {
  await db.query(
    `UPDATE subtitles
     SET status = $1, error_message = $2, updated_at = NOW()
     WHERE id = $3`,
    [status, errorMessage || null, subtitleId]
  );
}
```

---

### æ­¥é©Ÿ 7: å»ºç«‹å®Œæ•´çš„ STT API

å»ºç«‹ `backend/src/routes/subtitle.routes.ts`:

```typescript
/**
 * Subtitle Routes
 *
 * å­—å¹•ç›¸é—œçš„ API ç«¯é»
 */

import express from 'express';
import path from 'path';
import { v4 as uuidv4 } from 'uuid';
import { authenticateUser } from '../middleware/auth.middleware';
import * as audioExtractorService from '../services/audio-extractor.service';
import * as whisperService from '../services/whisper.service';
import * as subtitleFormatterService from '../services/subtitle-formatter.service';
import * as subtitleStorageService from '../services/subtitle-storage.service';

const router = express.Router();

/**
 * POST /api/videos/:videoId/subtitles
 *
 * ç‚ºå½±ç‰‡ç”Ÿæˆå­—å¹•
 */
router.post('/:videoId/subtitles', authenticateUser, async (req, res) => {
  const { videoId } = req.params;
  const { language } = req.body; // å¯é¸ï¼Œä¸æŒ‡å®šå‰‡è‡ªå‹•åµæ¸¬
  const userId = req.user!.id;

  try {
    // 1. å–å¾—å½±ç‰‡è³‡è¨Š
    const { db } = await import('../db');
    const videoResult = await db.query(
      'SELECT file_path FROM videos WHERE id = $1 AND user_id = $2',
      [videoId, userId]
    );

    if (videoResult.rows.length === 0) {
      return res.status(404).json({ error: 'Video not found' });
    }

    const videoPath = videoResult.rows[0].file_path;

    // 2. æº–å‚™å·¥ä½œç›®éŒ„
    const workDir = path.join('/tmp', 'whisper', uuidv4());

    // 3. æå–ä¸¦æº–å‚™éŸ³è»Œ
    const audioPaths = await audioExtractorService.prepareAudioForWhisper(
      videoPath,
      workDir
    );

    // 4. è½‰éŒ„éŸ³è¨Š
    const whisperResponse = audioPaths.length === 1
      ? await whisperService.transcribeAudio(audioPaths[0], language)
      : await whisperService.transcribeMultipleAudios(audioPaths, language);

    // 5. éæ¿¾ç„¡èªéŸ³ç‰‡æ®µ
    const filteredSegments = whisperService.filterSilentSegments(
      whisperResponse.segments
    );

    // 6. ç”Ÿæˆå­—å¹•æª”æ¡ˆ
    const subtitleText = subtitleFormatterService.generateSubtitle(
      filteredSegments
    );

    // 7. å„²å­˜åˆ°è³‡æ–™åº«å’Œ GCS
    const { subtitleId, filePath } = await subtitleStorageService.saveSubtitleToDatabase(
      videoId,
      { ...whisperResponse, segments: filteredSegments },
      subtitleText,
      userId
    );

    // 8. æ¸…ç†æš«å­˜æª”æ¡ˆ
    await audioExtractorService.cleanupAudioFiles(workDir);

    res.json({
      success: true,
      data: {
        subtitleId,
        filePath,
        language: whisperResponse.language,
        duration: whisperResponse.duration,
        segmentCount: filteredSegments.length,
        wordCount: whisperResponse.text.length,
      },
    });
  } catch (error: any) {
    console.error('Generate subtitle error:', error);
    res.status(500).json({ error: error.message || 'Failed to generate subtitle' });
  }
});

/**
 * GET /api/videos/:videoId/subtitles
 *
 * å–å¾—å½±ç‰‡çš„æ‰€æœ‰å­—å¹•
 */
router.get('/:videoId/subtitles', authenticateUser, async (req, res) => {
  const { videoId } = req.params;
  const userId = req.user!.id;

  try {
    const { db } = await import('../db');

    // é©—è­‰å½±ç‰‡æ“æœ‰æ¬Š
    const videoResult = await db.query(
      'SELECT id FROM videos WHERE id = $1 AND user_id = $2',
      [videoId, userId]
    );

    if (videoResult.rows.length === 0) {
      return res.status(404).json({ error: 'Video not found' });
    }

    const subtitles = await subtitleStorageService.getSubtitles(videoId);

    res.json({
      success: true,
      data: subtitles,
    });
  } catch (error: any) {
    console.error('Get subtitles error:', error);
    res.status(500).json({ error: error.message || 'Failed to get subtitles' });
  }
});

/**
 * GET /api/subtitles/:subtitleId/download
 *
 * ä¸‹è¼‰å­—å¹•æª”æ¡ˆ
 */
router.get('/:subtitleId/download', authenticateUser, async (req, res) => {
  const { subtitleId } = req.params;

  try {
    const { db } = await import('../db');

    const result = await db.query(
      `SELECT s.file_path, s.format, v.user_id
       FROM subtitles s
       JOIN videos v ON s.video_id = v.id
       WHERE s.id = $1`,
      [subtitleId]
    );

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Subtitle not found' });
    }

    const { file_path, format } = result.rows[0];

    // ç”Ÿæˆä¸‹è¼‰ URL
    const downloadUrl = await import('../services/storage.service').then(s =>
      s.generateDownloadUrl(file_path, 60)
    );

    res.json({
      success: true,
      data: {
        downloadUrl,
        format,
      },
    });
  } catch (error: any) {
    console.error('Download subtitle error:', error);
    res.status(500).json({ error: error.message || 'Failed to download subtitle' });
  }
});

export default router;
```

---

### æ­¥é©Ÿ 8: è¨»å†Šè·¯ç”±

åœ¨ `backend/src/index.ts` åŠ å…¥:

```typescript
import subtitleRoutes from './routes/subtitle.routes';

app.use('/api/videos', subtitleRoutes);
```

---

### æ­¥é©Ÿ 9: å‰ç«¯å‘¼å«ç¯„ä¾‹

å»ºç«‹ `frontend/lib/subtitle.ts`:

```typescript
/**
 * å‰ç«¯å­—å¹•å·¥å…·
 */

interface GenerateSubtitleOptions {
  language?: string; // èªè¨€ä»£ç¢¼ï¼Œä¸æŒ‡å®šå‰‡è‡ªå‹•åµæ¸¬
}

/**
 * ç‚ºå½±ç‰‡ç”Ÿæˆå­—å¹•
 */
export async function generateSubtitle(
  videoId: string,
  options: GenerateSubtitleOptions = {}
): Promise<{
  subtitleId: string;
  filePath: string;
  language: string;
  duration: number;
}> {
  const response = await fetch(`/api/videos/${videoId}/subtitles`, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      Authorization: `Bearer ${localStorage.getItem('token')}`,
    },
    body: JSON.stringify(options),
  });

  if (!response.ok) {
    const error = await response.json();
    throw new Error(error.error || 'Failed to generate subtitle');
  }

  const { data } = await response.json();
  return data;
}

/**
 * å–å¾—å½±ç‰‡çš„æ‰€æœ‰å­—å¹•
 */
export async function getSubtitles(videoId: string) {
  const response = await fetch(`/api/videos/${videoId}/subtitles`, {
    headers: {
      Authorization: `Bearer ${localStorage.getItem('token')}`,
    },
  });

  if (!response.ok) {
    throw new Error('Failed to get subtitles');
  }

  const { data } = await response.json();
  return data;
}

/**
 * ä¸‹è¼‰å­—å¹•æª”æ¡ˆ
 */
export async function downloadSubtitle(subtitleId: string): Promise<string> {
  const response = await fetch(`/api/subtitles/${subtitleId}/download`, {
    headers: {
      Authorization: `Bearer ${localStorage.getItem('token')}`,
    },
  });

  if (!response.ok) {
    throw new Error('Failed to download subtitle');
  }

  const { data } = await response.json();
  return data.downloadUrl;
}
```

---

## âœ… é©—æ”¶æ¨™æº–

å®Œæˆæ‰€æœ‰å¯¦ä½œæ­¥é©Ÿå¾Œ,åŸ·è¡Œé©—æ”¶æ¸¬è©¦ç¢ºèªä¸€åˆ‡æ­£å¸¸ã€‚

### æ¸¬è©¦ 1: éŸ³è»Œæå–æ¸¬è©¦

```bash
# æ¸¬è©¦ FFmpeg éŸ³è»Œæå–
ffmpeg -i test-video.mp4 -vn -acodec libmp3lame -b:a 64k test-audio.mp3

# æª¢æŸ¥éŸ³æª”
ffprobe test-audio.mp3 -show_format
```

**é€šéæ¨™æº–**: æˆåŠŸç”¢ç”Ÿ MP3 éŸ³æª”

---

### æ¸¬è©¦ 2: Whisper API æ¸¬è©¦

```bash
curl https://api.openai.com/v1/audio/transcriptions \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: multipart/form-data" \
  -F file="@test-audio.mp3" \
  -F model="whisper-1" \
  -F response_format="verbose_json"
```

**é æœŸå›æ‡‰**:
```json
{
  "task": "transcribe",
  "language": "zh",
  "duration": 10.5,
  "text": "æ¸¬è©¦æ–‡å­—å…§å®¹",
  "segments": [...]
}
```

---

### æ¸¬è©¦ 3: å®Œæ•´å­—å¹•ç”Ÿæˆ

```bash
curl -X POST http://localhost:8080/api/videos/VIDEO_ID/subtitles \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -d '{
    "language": "zh"
  }'
```

**é æœŸå›æ‡‰**:
```json
{
  "success": true,
  "data": {
    "subtitleId": "uuid",
    "filePath": "subtitles/user_123/subtitle_video_456.srt",
    "language": "zh",
    "duration": 120.5,
    "segmentCount": 45,
    "wordCount": 1200
  }
}
```

---

### æ¸¬è©¦ 4: å­—å¹•ä¸‹è¼‰

```bash
curl http://localhost:8080/api/subtitles/SUBTITLE_ID/download \
  -H "Authorization: Bearer YOUR_TOKEN"
```

**é€šéæ¨™æº–**: å–å¾—å­—å¹•æª”æ¡ˆä¸‹è¼‰ç¶²å€

---

## ğŸ“‹ å®Œæˆæª¢æŸ¥æ¸…å–®

å®Œæˆé€™å€‹ Task å¾Œ,è«‹ç¢ºèªä»¥ä¸‹é …ç›®:

### ç’°å¢ƒè¨­å®š
- [ ] OpenAI API Key å·²è¨­å®š
- [ ] FFmpeg å·²å®‰è£ä¸¦å¯ç”¨
- [ ] ç’°å¢ƒè®Šæ•¸å·²è¨­å®š

### æœå‹™å¯¦ä½œ
- [ ] éŸ³è»Œæå–æœå‹™å·²å»ºç«‹
- [ ] Whisper STT æœå‹™å·²å»ºç«‹
- [ ] å­—å¹•æ ¼å¼è½‰æ›å™¨å·²å»ºç«‹
- [ ] å­—å¹•å„²å­˜æœå‹™å·²å»ºç«‹

### è³‡æ–™åº«
- [ ] subtitles è¡¨å·²å»ºç«‹
- [ ] subtitle_segments è¡¨å·²å»ºç«‹
- [ ] ç´¢å¼•å·²å»ºç«‹

### API ç«¯é»
- [ ] POST /api/videos/:videoId/subtitles (ç”Ÿæˆå­—å¹•)
- [ ] GET /api/videos/:videoId/subtitles (æŸ¥è©¢å­—å¹•)
- [ ] GET /api/subtitles/:subtitleId/download (ä¸‹è¼‰å­—å¹•)

### åŠŸèƒ½é©—è­‰
- [ ] å¯ä»¥å¾å½±ç‰‡æå–éŸ³è»Œ
- [ ] å¯ä»¥å‘¼å« Whisper API
- [ ] å¯ä»¥ç”Ÿæˆ SRT/VTT å­—å¹•
- [ ] å­—å¹•æ­£ç¢ºå„²å­˜åˆ°è³‡æ–™åº«
- [ ] å¯ä»¥ä¸‹è¼‰å­—å¹•æª”æ¡ˆ

### é€²éšåŠŸèƒ½
- [ ] æ”¯æ´å¤šèªè¨€è¾¨è­˜
- [ ] è‡ªå‹•éæ¿¾ç„¡èªéŸ³ç‰‡æ®µ
- [ ] å¤§æª”æ¡ˆè‡ªå‹•åˆ‡åˆ†
- [ ] å­—å¹•é•·åº¦æ§åˆ¶

---

## ğŸ“Š Logging èˆ‡éŒ¯èª¤è™•ç†æ•´åˆ

> åƒè€ƒ: [LOGGING-STANDARDS.md](../LOGGING-STANDARDS.md)

### å¿…é ˆè¨˜éŒ„çš„äº‹ä»¶

#### åŸºç¤äº‹ä»¶
- [ ] `task_started` - ä»»å‹™é–‹å§‹
- [ ] `task_step_started` - é–‹å§‹ STT
- [ ] `task_step_completed` - STT å®Œæˆ
- [ ] `task_completed` - ä»»å‹™å®Œæˆ (åŒ…å«æˆæœ¬)
- [ ] `task_failed` - ä»»å‹™å¤±æ•—

#### AI å‘¼å«äº‹ä»¶
- [ ] `ai_call_started` - Whisper å‘¼å«é–‹å§‹
- [ ] `ai_call_completed` - è½‰éŒ„æˆåŠŸ (åŒ…å«æ™‚é•·ã€æˆæœ¬)
- [ ] `ai_call_failed` - Whisper API å¤±æ•—

### æ•´åˆç¨‹å¼ç¢¼ç¯„ä¾‹

```typescript
class STTEngine {
  async transcribe(voiceoverId: string, userId: string) {
    const taskLogger = createTaskLogger('stt_transcription', userId)
    const executionId = taskLogger.getExecutionId()
    const validator = new DataFlowValidator(taskLogger.getLogger())

    try {
      const voiceover = await db.voiceovers.findOne({ voiceoverId })

      await taskLogger.taskStarted(
        {
          voiceoverId,
          duration: voiceover.duration,
          filePath: voiceover.file_path
        },
        ['whisper_stt', 'save_transcript']
      )

      // Step 1: Whisper STT
      await taskLogger.stepStarted(0, 'whisper_stt')

      const aiLogger = taskLogger.createAILogger('openai_whisper', 'stt')

      await aiLogger.callStarted({
        file: voiceover.file_path,
        language: 'zh',
        duration: voiceover.duration
      })

      const startTime = Date.now()
      const result = await openai.audio.transcriptions.create({
        file: fs.createReadStream(voiceover.file_path),
        model: 'whisper-1',
        language: 'zh',
        response_format: 'verbose_json'
      })
      const duration = Date.now() - startTime

      // è¨ˆç®—æˆæœ¬ (æŒ‰éŸ³æª”åˆ†é˜æ•¸)
      const cost = (voiceover.duration / 60) * 0.006

      await aiLogger.callCompleted(
        {
          transcript_length: result.text.length,
          segments_count: result.segments?.length || 0,
          language: result.language
        },
        cost
      )

      // é©—è­‰è½‰éŒ„çµæœ
      if (!result.text || result.text.trim().length === 0) {
        await taskLogger.getLogger().error('ai_response_validation_failed', {
          validation_error: 'EmptyTranscript',
          error_message: 'Whisper returned empty transcript',
          voiceover_id: voiceoverId,
          audio_duration: voiceover.duration
        })
        throw new ValidationError('Empty transcript from Whisper')
      }

      await taskLogger.stepCompleted(0, 'whisper_stt', {
        transcript_length: result.text.length,
        duration_ms: duration,
        cost
      })

      // Step 2: å„²å­˜è½‰éŒ„
      await taskLogger.stepStarted(1, 'save_transcript')
      await db.voiceovers.update(voiceoverId, {
        transcript: result.text,
        transcript_segments: result.segments
      })
      await taskLogger.stepCompleted(1, 'save_transcript')

      await taskLogger.taskCompleted(
        { transcript_length: result.text.length },
        cost
      )

      return result

    } catch (error) {
      await taskLogger.taskFailed('whisper_stt', error, {
        voiceoverId,
        audioDuration: voiceover?.duration
      })
      throw error  // âœ… Fail Fast
    }
  }
}
```

### å¿…é ˆé©—è­‰çš„è³‡æ–™

- [ ] è½‰éŒ„æ–‡å­—éç©º
- [ ] éŸ³æª”æ ¼å¼æ­£ç¢º (mp3, wav, m4a)
- [ ] éŸ³æª”æ™‚é•·èˆ‡é æœŸç›¸ç¬¦

### Fail Fast æª¢æŸ¥æ¸…å–®

- [x] âœ… éŸ³æª”æ ¼å¼éŒ¯èª¤æ™‚ç«‹å³ throw error
- [x] âœ… è½‰éŒ„çµæœç‚ºç©ºæ™‚ç«‹å³ throw error
- [x] âœ… è¨˜éŒ„å®Œæ•´éŒ¯èª¤ä¸Šä¸‹æ–‡ (file path, duration, error details)

---

## ğŸ› å¸¸è¦‹å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ

### å•é¡Œ 1: API Key ç„¡æ•ˆ

**éŒ¯èª¤è¨Šæ¯:**
```
Error: Invalid API key provided
```

**è§£æ±ºæ–¹æ¡ˆ**:

1. **æª¢æŸ¥ API Key**:
```bash
echo $OPENAI_API_KEY
```

2. **ç¢ºèª API Key æœ‰æ•ˆ**:
```bash
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

3. **æª¢æŸ¥é¡åº¦**:
- å‰å¾€ https://platform.openai.com/usage
- ç¢ºèªæœ‰è¶³å¤ çš„é¡åº¦

---

### å•é¡Œ 2: æª”æ¡ˆéå¤§éŒ¯èª¤

**éŒ¯èª¤è¨Šæ¯:**
```
Error: File is too large. Maximum file size is 25MB
```

**è§£æ±ºæ–¹æ¡ˆ**:

1. **é™ä½éŸ³è³ª**:
```typescript
// åœ¨ whisper.config.ts èª¿æ•´
audioBitrate: '32k', // å¾ 64k é™åˆ° 32k
```

2. **è‡ªå‹•åˆ‡åˆ†**:
```typescript
// prepareAudioForWhisper å·²å¯¦ä½œè‡ªå‹•åˆ‡åˆ†
if (fileSize > 25MB) {
  return await splitAudio(audioPath, segmentsDir);
}
```

---

### å•é¡Œ 3: èªè¨€è¾¨è­˜éŒ¯èª¤

**éŒ¯èª¤è¨Šæ¯:**
```
Detected language: en, but video is in Chinese
```

**è§£æ±ºæ–¹æ¡ˆ**:

1. **æ˜ç¢ºæŒ‡å®šèªè¨€**:
```typescript
const response = await transcribeAudio(audioPath, 'zh');
```

2. **æª¢æŸ¥éŸ³è¨Šå“è³ª**:
```bash
ffprobe audio.mp3 -show_streams
```

3. **æé«˜éŸ³è³ª**:
```typescript
audioBitrate: '128k', // æé«˜è‡³ 128k
```

---

### å•é¡Œ 4: å­—å¹•æ™‚é–“è»¸ä¸åŒæ­¥

**å•é¡Œ**: å­—å¹•æ™‚é–“èˆ‡å½±ç‰‡ä¸ä¸€è‡´

**åŸå› **: éŸ³è»Œæå–æ™‚æ”¹è®Šäº†æ™‚é•·

**è§£æ±ºæ–¹æ¡ˆ**:

1. **ä½¿ç”¨åŸå§‹å¹€ç‡**:
```bash
ffmpeg -i video.mp4 -vn -acodec libmp3lame -ar 44100 audio.mp3
```

2. **é©—è­‰éŸ³è¨Šæ™‚é•·**:
```bash
ffprobe -v error -show_entries format=duration \
  -of default=noprint_wrappers=1:nokey=1 audio.mp3
```

3. **å°é½Šæ™‚é–“è»¸**:
```typescript
// å¦‚æœæ™‚é•·ä¸ä¸€è‡´ï¼ŒæŒ‰æ¯”ä¾‹èª¿æ•´
const ratio = videoDuration / audioDuration;
segments.forEach(seg => {
  seg.start *= ratio;
  seg.end *= ratio;
});
```

---

### å•é¡Œ 5: Rate Limit éŒ¯èª¤

**éŒ¯èª¤è¨Šæ¯:**
```
Error: Rate limit exceeded
```

**è§£æ±ºæ–¹æ¡ˆ**:

1. **åŠ å…¥å»¶é²**:
```typescript
async function transcribeWithRetry(audioPath: string, retries = 3) {
  for (let i = 0; i < retries; i++) {
    try {
      return await transcribeAudio(audioPath);
    } catch (error: any) {
      if (error.message.includes('rate_limit') && i < retries - 1) {
        await new Promise(resolve => setTimeout(resolve, 2000)); // ç­‰å¾… 2 ç§’
        continue;
      }
      throw error;
    }
  }
}
```

2. **æ‰¹æ¬¡è™•ç†é–“éš”**:
```typescript
for (const audioPath of audioPaths) {
  const result = await transcribeAudio(audioPath);
  results.push(result);
  await new Promise(resolve => setTimeout(resolve, 1000)); // æ¯å€‹è«‹æ±‚é–“éš” 1 ç§’
}
```

---

## ğŸ“š å»¶ä¼¸å­¸ç¿’è³‡æº

å¦‚æœä½ æƒ³æ·±å…¥äº†è§£é€™å€‹ Task ä½¿ç”¨çš„æŠ€è¡“:

- **OpenAI Whisper API**: https://platform.openai.com/docs/guides/speech-to-text
- **FFmpeg Audio Processing**: https://trac.ffmpeg.org/wiki/AudioChannelManipulation
- **SRT Format Spec**: https://en.wikipedia.org/wiki/SubRip
- **WebVTT Standard**: https://www.w3.org/TR/webvtt1/
- **Whisper Model Paper**: https://arxiv.org/abs/2212.04356

---

## âœ… Task å®Œæˆç¢ºèª

ç•¶ä»¥ä¸‹æ‰€æœ‰é …ç›®éƒ½å®Œæˆæ™‚,é€™å€‹ Task å°±ç®—å®Œæˆ:

1. âœ… OpenAI Whisper API å·²è¨­å®š
2. âœ… éŸ³è»Œæå–åŠŸèƒ½æ­£å¸¸
3. âœ… èªéŸ³è¾¨è­˜å¯ä»¥é‹ä½œ
4. âœ… å­—å¹•æ ¼å¼æ­£ç¢ºç”Ÿæˆ
5. âœ… è³‡æ–™åº«å„²å­˜æ­£å¸¸
6. âœ… æ‰€æœ‰ API ç«¯é»æ­£å¸¸

### æœ€çµ‚é©—æ”¶æŒ‡ä»¤

```bash
# 1. æ¸¬è©¦éŸ³è»Œæå–
npm run test:audio-extract

# 2. æ¸¬è©¦ Whisper API
npm run test:whisper

# 3. æ¸¬è©¦å­—å¹•ç”Ÿæˆ
npm run test:subtitle

# 4. å®Œæ•´ E2E æ¸¬è©¦
npm test -- subtitle.e2e.test.ts
```

**æ­å–œ!** å¦‚æœæ‰€æœ‰é©—æ”¶éƒ½é€šé,ä»£è¡¨ Task 2.5 å®Œæˆäº†!

---

**ä¸‹ä¸€æ­¥**: Task 2.6 - èªæ„åˆ†æèˆ‡å ´æ™¯åˆ‡åˆ†

---

**æ–‡ä»¶ç‰ˆæœ¬**: 1.0
**ç‹€æ…‹**: âœ… å·²å®Œæˆ
**æœ€å¾Œæ›´æ–°**: 2025-10-07
**ç¶­è­·è€…**: CheapCut é–‹ç™¼åœ˜éšŠ
