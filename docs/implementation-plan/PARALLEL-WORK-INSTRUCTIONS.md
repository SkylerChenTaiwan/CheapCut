# å¹³è¡Œå·¥ä½œæŒ‡ç¤º - Logging æ•´åˆæ‰¹æ¬¡æ›´æ–°

**ç›®çš„**: å°‡å‰©é¤˜ 16 å€‹ Tasks åŠ å…¥æ¨™æº–çš„ Logging ç« ç¯€
**æ¨™æº–æ–‡ä»¶**: `docs/implementation-plan/LOGGING-STANDARDS.md`
**é€²åº¦è¿½è¹¤**: `docs/implementation-plan/LOGGING-INTEGRATION-STATUS.md`

---

## ğŸ“‹ å·²å®Œæˆçš„ç¯„ä¾‹

è«‹åƒè€ƒä»¥ä¸‹**å·²å®Œæˆ**çš„ Tasks ä½œç‚ºæ¨¡æ¿:
- âœ… `phase-1-infrastructure/task-1.5-logger-service.md` (Step 6-7: é©—è­‰æ¡†æ¶)
- âœ… `phase-2-engines/task-2.0-prompt-management.md` (ğŸ“Š Logging ç« ç¯€)

---

## ğŸ¯ å·¥ä½œåˆ†é…

æ¯å€‹ Claude Code è² è²¬ 2-3 å€‹ Tasksï¼ŒæŒ‰ç…§ä»¥ä¸‹ prompts åŸ·è¡Œã€‚

---

## Prompt 1: Task 2.2 (Video Analysis) + Task 2.3 (Tag Conversion)

**è² è²¬äºº**: Claude Code #1

### Task 2.2: Google Video AI æ•´åˆ

**æª”æ¡ˆ**: `docs/implementation-plan/phase-2-engines/task-2.2-video-analysis.md`

**æ’å…¥ä½ç½®**: åœ¨æ–‡ä»¶æœ«å°¾çš„ã€Œå¸¸è¦‹å•é¡Œã€ç« ç¯€**ä¹‹å‰**æ’å…¥ä»¥ä¸‹å®Œæ•´ç« ç¯€

**æ’å…¥å…§å®¹**:

```markdown
---

## ğŸ“Š Logging èˆ‡éŒ¯èª¤è™•ç†æ•´åˆ

> åƒè€ƒ: [LOGGING-STANDARDS.md](../LOGGING-STANDARDS.md)

### å¿…é ˆè¨˜éŒ„çš„äº‹ä»¶

#### åŸºç¤äº‹ä»¶ (TaskLogger)
- [ ] `task_started` - ä»»å‹™é–‹å§‹
- [ ] `task_step_started` - é–‹å§‹å‘¼å« Video AI
- [ ] `task_step_completed` - Video AI åˆ†æå®Œæˆ
- [ ] `task_completed` - ä»»å‹™å®Œæˆ (åŒ…å«ç¸½æˆæœ¬)
- [ ] `task_failed` - ä»»å‹™å¤±æ•—

#### AI å‘¼å«äº‹ä»¶
- [ ] `ai_call_started` - Google Video AI å‘¼å«é–‹å§‹
- [ ] `ai_call_completed` - åˆ†ææˆåŠŸ (åŒ…å«å ´æ™¯æ•¸ã€æ¨™ç±¤æ•¸ã€æˆæœ¬)
- [ ] `ai_call_failed` - API å¤±æ•— (åŒ…å« status code, error details)
- [ ] `ai_response_validation_failed` - å›æ‡‰æ ¼å¼é©—è­‰å¤±æ•—

### æ•´åˆç¨‹å¼ç¢¼ç¯„ä¾‹

```typescript
class VideoAnalysisEngine {
  async analyze(videoId: string, userId: string) {
    // å»ºç«‹ TaskLogger
    const taskLogger = createTaskLogger('video_analysis', userId)
    const executionId = taskLogger.getExecutionId()
    const validator = new DataFlowValidator(taskLogger.getLogger())

    try {
      const video = await db.videos.findOne({ videoId })

      // è¨˜éŒ„ä»»å‹™é–‹å§‹
      await taskLogger.taskStarted(
        {
          videoId,
          duration: video.duration,
          filePath: video.file_path
        },
        ['call_video_ai', 'process_results']
      )

      // Step 1: å‘¼å« Video AI
      await taskLogger.stepStarted(0, 'call_video_ai')

      const aiLogger = taskLogger.createAILogger('google_video_ai', 'video_analysis')

      await aiLogger.callStarted({
        videoUri: video.file_path,
        features: ['LABEL_DETECTION', 'SHOT_CHANGE_DETECTION'],
        videoDuration: video.duration
      })

      const startTime = Date.now()
      const result = await googleVideoAI.annotateVideo({
        inputUri: video.file_path,
        features: ['LABEL_DETECTION', 'SHOT_CHANGE_DETECTION']
      })
      const duration = Date.now() - startTime

      // è¨ˆç®—æˆæœ¬ (æŒ‰å½±ç‰‡åˆ†é˜æ•¸)
      const cost = (video.duration / 60) * 0.10

      await aiLogger.callCompleted(
        {
          scenes_detected: result.shotAnnotations?.length || 0,
          labels_count: result.labelAnnotations?.length || 0
        },
        cost
      )

      // é©—è­‰ AI å›æ‡‰ (åŸºæœ¬æª¢æŸ¥)
      if (!result.shotAnnotations || result.shotAnnotations.length === 0) {
        await taskLogger.getLogger().error('ai_response_validation_failed', {
          validation_error: 'EmptyResult',
          error_message: 'No shot annotations returned',
          video_id: videoId,
          video_duration: video.duration
        })
        throw new ValidationError('Video AI returned no shot annotations')
      }

      await taskLogger.stepCompleted(0, 'call_video_ai', {
        scenes: result.shotAnnotations.length,
        labels: result.labelAnnotations.length,
        duration_ms: duration,
        cost
      })

      // Step 2: è™•ç†çµæœ
      await taskLogger.stepStarted(1, 'process_results')
      // ... è™•ç†é‚è¼¯ ...
      await taskLogger.stepCompleted(1, 'process_results')

      // ä»»å‹™å®Œæˆ
      await taskLogger.taskCompleted(
        {
          scenes_created: result.shotAnnotations.length,
          labels_created: result.labelAnnotations.length
        },
        cost
      )

      return result

    } catch (error) {
      await taskLogger.taskFailed('call_video_ai', error, {
        videoId,
        videoDuration: video?.duration
      })
      throw error  // âœ… Fail Fast
    }
  }
}
```

### å¿…é ˆé©—è­‰çš„è³‡æ–™

- [ ] AI å›æ‡‰éç©º (è‡³å°‘æœ‰ 1 å€‹ shot annotation)
- [ ] å ´æ™¯æ™‚é–“ç¯„åœæœ‰æ•ˆ (start < end, ä¸è¶…éå½±ç‰‡é•·åº¦)
- [ ] æ¨™ç±¤ä¿¡å¿ƒåº¦åœ¨ 0-1 ä¹‹é–“

### Fail Fast æª¢æŸ¥æ¸…å–®

- [x] âœ… API å¤±æ•—æ™‚ç«‹å³ throw error
- [x] âœ… å›æ‡‰ç‚ºç©ºæ™‚ç«‹å³ throw error
- [x] âœ… è¨˜éŒ„å®Œæ•´éŒ¯èª¤ä¸Šä¸‹æ–‡ (videoId, API response)
- [x] âŒ ä¸ä½¿ç”¨ fallback æˆ–é è¨­å€¼

---
```

### Task 2.3: Tag Conversion

**æª”æ¡ˆ**: `docs/implementation-plan/phase-2-engines/task-2.3-tag-conversion.md`

**æ’å…¥ä½ç½®**: åŒæ¨£åœ¨æ–‡ä»¶æœ«å°¾çš„å¸¸è¦‹å•é¡Œä¹‹å‰

**æ’å…¥å…§å®¹**:

```markdown
---

## ğŸ“Š Logging èˆ‡éŒ¯èª¤è™•ç†æ•´åˆ

> åƒè€ƒ: [LOGGING-STANDARDS.md](../LOGGING-STANDARDS.md)

### å¿…é ˆè¨˜éŒ„çš„äº‹ä»¶

#### åŸºç¤äº‹ä»¶
- [ ] `task_step_started` - é–‹å§‹æ¨™ç±¤è½‰æ›
- [ ] `task_step_completed` - è½‰æ›å®Œæˆ
- [ ] `data_flow_validation_failed` - è½‰æ›çµæœé©—è­‰å¤±æ•—

### æ•´åˆç¨‹å¼ç¢¼ç¯„ä¾‹

```typescript
class TagConversionEngine {
  async convert(videoAIResult: any, taskLogger: TaskLogger) {
    const validator = new DataFlowValidator(taskLogger.getLogger())

    try {
      await taskLogger.stepStarted(stepIndex, 'convert_tags')

      // è½‰æ›æ¨™ç±¤
      const tags = this.convertLabelsToTags(videoAIResult.labelAnnotations)

      // é©—è­‰è½‰æ›çµæœ
      if (tags.length === 0) {
        await taskLogger.getLogger().warn('data_flow_validation_failed', {
          validation_error: 'EmptyResult',
          error_message: 'Tag conversion returned no tags',
          input_labels_count: videoAIResult.labelAnnotations?.length || 0
        })
      }

      // é©—è­‰æ¨™ç±¤æ ¼å¼
      for (const tag of tags) {
        if (!tag.category || !tag.name) {
          await taskLogger.getLogger().error('data_flow_validation_failed', {
            validation_error: 'InvalidTagFormat',
            error_message: 'Tag missing required fields',
            tag
          })
          throw new ValidationError('Invalid tag format')
        }
      }

      await taskLogger.stepCompleted(stepIndex, 'convert_tags', {
        tags_created: tags.length,
        categories: [...new Set(tags.map(t => t.category))]
      })

      return tags

    } catch (error) {
      throw error  // âœ… Fail Fast
    }
  }
}
```

### Fail Fast æª¢æŸ¥æ¸…å–®

- [x] âœ… æ¨™ç±¤æ ¼å¼éŒ¯èª¤æ™‚ç«‹å³ throw error
- [x] âš ï¸  è½‰æ›çµæœç‚ºç©ºæ™‚è¨˜éŒ„ WARN (å¯èƒ½æ˜¯å½±ç‰‡å…§å®¹å•é¡Œ)
- [x] âœ… è¨˜éŒ„è½‰æ›çµ±è¨ˆè³‡è¨Š

---
```

**æäº¤è¨Šæ¯**:
```bash
git add docs/implementation-plan/phase-2-engines/task-2.{2,3}*.md
git commit -m "feat(docs): Task 2.2-2.3 åŠ å…¥ Logging æ•´åˆ

- Task 2.2: Video Analysis å®Œæ•´ TaskLogger ç¯„ä¾‹
- Task 2.3: Tag Conversion è³‡æ–™é©—è­‰

æ ¹æ“š LOGGING-STANDARDS.md

ğŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude <noreply@anthropic.com>"
git push
```

---

## Prompt 2: Task 2.5 (STT) + Task 2.6 (Semantic Analysis)

**è² è²¬äºº**: Claude Code #2

### Task 2.5: STT Integration (Whisper)

**æª”æ¡ˆ**: `docs/implementation-plan/phase-2-engines/task-2.5-stt-integration.md`

**æ’å…¥ä½ç½®**: åœ¨ã€Œå¸¸è¦‹å•é¡Œã€ä¹‹å‰

**æ’å…¥å…§å®¹**:

```markdown
---

## ğŸ“Š Logging èˆ‡éŒ¯èª¤è™•ç†æ•´åˆ

> åƒè€ƒ: [LOGGING-STANDARDS.md](../LOGGING-STANDARDS.md)

### å¿…é ˆè¨˜éŒ„çš„äº‹ä»¶

#### åŸºç¤äº‹ä»¶
- [ ] `task_started` - ä»»å‹™é–‹å§‹
- [ ] `task_step_started` - é–‹å§‹ STT
- [ ] `task_step_completed` - STT å®Œæˆ
- [ ] `task_completed` - ä»»å‹™å®Œæˆ (åŒ…å«æˆæœ¬)
- [ ] `task_failed` - ä»»å‹™å¤±æ•—

#### AI å‘¼å«äº‹ä»¶
- [ ] `ai_call_started` - Whisper å‘¼å«é–‹å§‹
- [ ] `ai_call_completed` - è½‰éŒ„æˆåŠŸ (åŒ…å«æ™‚é•·ã€æˆæœ¬)
- [ ] `ai_call_failed` - Whisper API å¤±æ•—

### æ•´åˆç¨‹å¼ç¢¼ç¯„ä¾‹

```typescript
class STTEngine {
  async transcribe(voiceoverId: string, userId: string) {
    const taskLogger = createTaskLogger('stt_transcription', userId)
    const executionId = taskLogger.getExecutionId()
    const validator = new DataFlowValidator(taskLogger.getLogger())

    try {
      const voiceover = await db.voiceovers.findOne({ voiceoverId })

      await taskLogger.taskStarted(
        {
          voiceoverId,
          duration: voiceover.duration,
          filePath: voiceover.file_path
        },
        ['whisper_stt', 'save_transcript']
      )

      // Step 1: Whisper STT
      await taskLogger.stepStarted(0, 'whisper_stt')

      const aiLogger = taskLogger.createAILogger('openai_whisper', 'stt')

      await aiLogger.callStarted({
        file: voiceover.file_path,
        language: 'zh',
        duration: voiceover.duration
      })

      const startTime = Date.now()
      const result = await openai.audio.transcriptions.create({
        file: fs.createReadStream(voiceover.file_path),
        model: 'whisper-1',
        language: 'zh',
        response_format: 'verbose_json'
      })
      const duration = Date.now() - startTime

      // è¨ˆç®—æˆæœ¬ (æŒ‰éŸ³æª”åˆ†é˜æ•¸)
      const cost = (voiceover.duration / 60) * 0.006

      await aiLogger.callCompleted(
        {
          transcript_length: result.text.length,
          segments_count: result.segments?.length || 0,
          language: result.language
        },
        cost
      )

      // é©—è­‰è½‰éŒ„çµæœ
      if (!result.text || result.text.trim().length === 0) {
        await taskLogger.getLogger().error('ai_response_validation_failed', {
          validation_error: 'EmptyTranscript',
          error_message: 'Whisper returned empty transcript',
          voiceover_id: voiceoverId,
          audio_duration: voiceover.duration
        })
        throw new ValidationError('Empty transcript from Whisper')
      }

      await taskLogger.stepCompleted(0, 'whisper_stt', {
        transcript_length: result.text.length,
        duration_ms: duration,
        cost
      })

      // Step 2: å„²å­˜è½‰éŒ„
      await taskLogger.stepStarted(1, 'save_transcript')
      await db.voiceovers.update(voiceoverId, {
        transcript: result.text,
        transcript_segments: result.segments
      })
      await taskLogger.stepCompleted(1, 'save_transcript')

      await taskLogger.taskCompleted(
        { transcript_length: result.text.length },
        cost
      )

      return result

    } catch (error) {
      await taskLogger.taskFailed('whisper_stt', error, {
        voiceoverId,
        audioDuration: voiceover?.duration
      })
      throw error  // âœ… Fail Fast
    }
  }
}
```

### å¿…é ˆé©—è­‰çš„è³‡æ–™

- [ ] è½‰éŒ„æ–‡å­—éç©º
- [ ] éŸ³æª”æ ¼å¼æ­£ç¢º (mp3, wav, m4a)
- [ ] éŸ³æª”æ™‚é•·èˆ‡é æœŸç›¸ç¬¦

### Fail Fast æª¢æŸ¥æ¸…å–®

- [x] âœ… éŸ³æª”æ ¼å¼éŒ¯èª¤æ™‚ç«‹å³ throw error
- [x] âœ… è½‰éŒ„çµæœç‚ºç©ºæ™‚ç«‹å³ throw error
- [x] âœ… è¨˜éŒ„å®Œæ•´éŒ¯èª¤ä¸Šä¸‹æ–‡ (file path, duration, error details)

---
```

### Task 2.6: Semantic Analysis (GPT-4)

**æª”æ¡ˆ**: `docs/implementation-plan/phase-2-engines/task-2.6-semantic-analysis.md`

**æ’å…¥ä½ç½®**: åœ¨ã€Œå¸¸è¦‹å•é¡Œã€ä¹‹å‰

**æ’å…¥å…§å®¹**:

```markdown
---

## ğŸ“Š Logging èˆ‡éŒ¯èª¤è™•ç†æ•´åˆ

> åƒè€ƒ: [LOGGING-STANDARDS.md](../LOGGING-STANDARDS.md)

### å¿…é ˆè¨˜éŒ„çš„äº‹ä»¶

#### åŸºç¤äº‹ä»¶
- [ ] `task_started` - ä»»å‹™é–‹å§‹
- [ ] `task_step_started` - é–‹å§‹èªæ„åˆ†æ
- [ ] `task_step_completed` - åˆ†æå®Œæˆ
- [ ] `task_completed` - ä»»å‹™å®Œæˆ (åŒ…å«æˆæœ¬)
- [ ] `task_failed` - ä»»å‹™å¤±æ•—

#### AI å‘¼å«äº‹ä»¶ (é€é PromptManager è‡ªå‹•è¨˜éŒ„)
- [ ] `ai_call_started` - GPT-4 å‘¼å«é–‹å§‹
- [ ] `ai_call_completed` - åˆ†ææˆåŠŸ
- [ ] `ai_call_failed` - GPT-4 å¤±æ•—
- [ ] `ai_response_validation_failed` - Schema é©—è­‰å¤±æ•—

### æ•´åˆç¨‹å¼ç¢¼ç¯„ä¾‹

```typescript
class SemanticAnalysisEngine {
  async analyze(transcript: string, userId: string) {
    const taskLogger = createTaskLogger('semantic_analysis', userId)
    const executionId = taskLogger.getExecutionId()
    const validator = new DataFlowValidator(taskLogger.getLogger())
    const callId = uuid()

    try {
      await taskLogger.taskStarted(
        { transcript_length: transcript.length },
        ['ai_analysis', 'save_results']
      )

      // Step 1: AI èªæ„åˆ†æ
      await taskLogger.stepStarted(0, 'ai_analysis')

      // é€é PromptManager å‘¼å« (è‡ªå‹•è¨˜éŒ„ AI å‘¼å«èˆ‡æˆæœ¬)
      const { response, cost } = await promptManager.executePrompt(
        'voiceover-processing',
        'semantic-analysis',
        { transcript, language: 'zh-TW' },
        { executionId, userId, callId }
      )

      // âœ… é©—è­‰ AI å›æ‡‰ Schema
      await validator.validateAIResponse(
        callId,
        'semantic_analysis',  // åœ¨ schemas.ts ä¸­å·²å®šç¾©
        response,
        // é¡å¤–æ¥­å‹™é‚è¼¯é©—è­‰
        (data) => {
          const errors = []

          // é—œéµå­—ä¸æ‡‰è©²è¶…é 20 å€‹
          if (data.keywords.length > 20) {
            errors.push({
              field: 'keywords',
              message: 'Too many keywords (max 20)',
              value: data.keywords.length
            })
          }

          // topics è‡³å°‘è¦æœ‰ 1 å€‹
          if (data.topics.length === 0) {
            errors.push({
              field: 'topics',
              message: 'Must have at least 1 topic',
              value: data.topics.length
            })
          }

          return errors
        }
      )

      await taskLogger.stepCompleted(0, 'ai_analysis', {
        topics_count: response.topics.length,
        keywords_count: response.keywords.length,
        tone: response.tone
      })

      // Step 2: å„²å­˜çµæœ
      await taskLogger.stepStarted(1, 'save_results')
      await db.voiceovers.update(voiceoverId, {
        semantic_analysis: response
      })
      await taskLogger.stepCompleted(1, 'save_results')

      await taskLogger.taskCompleted(
        {
          topics: response.topics.length,
          keywords: response.keywords.length
        },
        cost
      )

      return response

    } catch (error) {
      await taskLogger.taskFailed('ai_analysis', error, {
        transcript_length: transcript.length
      })
      throw error  // âœ… Fail Fast
    }
  }
}
```

### å¿…é ˆé©—è­‰çš„è³‡æ–™

æ ¹æ“š `schemas.ts` ä¸­çš„å®šç¾©:

- [x] `topics`: string[] (min 1, required)
- [x] `keywords`: string[] (min 1, max 20, required)
- [x] `tone`: 'professional' | 'casual' | 'enthusiastic' (required)

### Fail Fast æª¢æŸ¥æ¸…å–®

- [x] âœ… Schema é©—è­‰å¤±æ•—æ™‚ç«‹å³ throw error
- [x] âœ… æ¥­å‹™é‚è¼¯é©—è­‰å¤±æ•—æ™‚ç«‹å³ throw error
- [x] âœ… è¨˜éŒ„å®Œæ•´ AI å›æ‡‰ (ç”¨æ–¼ debug)
- [x] âŒ ä¸ä½¿ç”¨é è¨­å€¼æˆ– fallback

---
```

**æäº¤è¨Šæ¯**:
```bash
git add docs/implementation-plan/phase-2-engines/task-2.{5,6}*.md
git commit -m "feat(docs): Task 2.5-2.6 åŠ å…¥ Logging æ•´åˆ

- Task 2.5: Whisper STT å®Œæ•´è¨˜éŒ„èˆ‡æˆæœ¬è¿½è¹¤
- Task 2.6: Semantic Analysis Schema é©—è­‰

æ ¹æ“š LOGGING-STANDARDS.md

ğŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude <noreply@anthropic.com>"
git push
```

---

## Prompt 3: Task 2.7 (Voiceover Split) + Task 2.9 (AI Selection)

**è² è²¬äºº**: Claude Code #3

### Task 2.7: Voiceover Split (GPT-4)

**æª”æ¡ˆ**: `docs/implementation-plan/phase-2-engines/task-2.7-voiceover-split.md`

**æ’å…¥ä½ç½®**: åœ¨ã€Œå¸¸è¦‹å•é¡Œã€ä¹‹å‰

**æ’å…¥å…§å®¹**:

```markdown
---

## ğŸ“Š Logging èˆ‡éŒ¯èª¤è™•ç†æ•´åˆ

> åƒè€ƒ: [LOGGING-STANDARDS.md](../LOGGING-STANDARDS.md)

### å¿…é ˆè¨˜éŒ„çš„äº‹ä»¶

#### åŸºç¤äº‹ä»¶
- [ ] `task_started` - ä»»å‹™é–‹å§‹
- [ ] `task_step_started` - é–‹å§‹é…éŸ³åˆ‡åˆ†
- [ ] `task_step_completed` - åˆ‡åˆ†å®Œæˆ
- [ ] `task_completed` - ä»»å‹™å®Œæˆ
- [ ] `task_failed` - ä»»å‹™å¤±æ•—

#### AI å‘¼å«äº‹ä»¶ (é€é PromptManager)
- [ ] `ai_call_started`, `ai_call_completed`, `ai_call_failed`
- [ ] `ai_response_validation_failed` - Schema æˆ–æ™‚é–“è»¸é©—è­‰å¤±æ•—

### æ•´åˆç¨‹å¼ç¢¼ç¯„ä¾‹

```typescript
import { validateVoiceoverTiming } from '@/services/validators/data-flow.validator'

class VoiceoverSplitEngine {
  async split(voiceoverId: string, userId: string) {
    const taskLogger = createTaskLogger('voiceover_split', userId)
    const executionId = taskLogger.getExecutionId()
    const validator = new DataFlowValidator(taskLogger.getLogger())
    const callId = uuid()

    try {
      const voiceover = await db.voiceovers.findOne({ voiceoverId })

      await taskLogger.taskStarted(
        {
          voiceoverId,
          transcript_length: voiceover.transcript.length,
          duration: voiceover.duration
        },
        ['ai_split', 'validate_timing', 'save_segments']
      )

      // Step 1: AI åˆ‡åˆ†
      await taskLogger.stepStarted(0, 'ai_split')

      const { response, cost } = await promptManager.executePrompt(
        'voiceover-processing',
        'voiceover-split',
        {
          transcript: voiceover.transcript,
          duration: voiceover.duration
        },
        { executionId, userId, callId }
      )

      // âœ… é©—è­‰ Schema
      await validator.validateAIResponse(
        callId,
        'voiceover_split',  // åœ¨ schemas.ts ä¸­å·²å®šç¾©
        response
      )

      await taskLogger.stepCompleted(0, 'ai_split', {
        segments_count: response.segments.length
      })

      // Step 2: é©—è­‰æ™‚é–“è»¸ä¸€è‡´æ€§ âœ… é—œéµé©—è­‰ï¼
      await taskLogger.stepStarted(1, 'validate_timing')

      await validateVoiceoverTiming(
        response.segments,
        voiceover.duration,
        taskLogger.getLogger()
      )

      await taskLogger.stepCompleted(1, 'validate_timing')

      // Step 3: å„²å­˜ç‰‡æ®µ
      await taskLogger.stepStarted(2, 'save_segments')
      // ... å„²å­˜é‚è¼¯ ...
      await taskLogger.stepCompleted(2, 'save_segments')

      await taskLogger.taskCompleted(
        { segments_created: response.segments.length },
        cost
      )

      return response.segments

    } catch (error) {
      await taskLogger.taskFailed('ai_split', error, {
        voiceoverId,
        duration: voiceover?.duration
      })
      throw error  // âœ… Fail Fast
    }
  }
}
```

### å¿…é ˆé©—è­‰çš„è³‡æ–™

æ ¹æ“š `schemas.ts`:
- [x] `segments`: array (min 1)
- [x] æ¯å€‹ segment: `{ start: number, end: number, text: string, keywords: string[] }`

**æ™‚é–“è»¸ä¸€è‡´æ€§** (ä½¿ç”¨ `validateVoiceoverTiming`):
- [x] start < end
- [x] ç„¡ç¸«éš™ (segment[i].end == segment[i+1].start)
- [x] ç„¡é‡ç–Š
- [x] ä¸è¶…éç¸½é•·åº¦

### Fail Fast æª¢æŸ¥æ¸…å–®

- [x] âœ… Schema é©—è­‰å¤±æ•—æ™‚ç«‹å³ throw error
- [x] âœ… æ™‚é–“è»¸é©—è­‰å¤±æ•—æ™‚ç«‹å³ throw error (ä¸å˜—è©¦ä¿®å¾©)
- [x] âœ… è¨˜éŒ„è©³ç´°çš„æ™‚é–“è»¸éŒ¯èª¤ (å“ªå€‹ segment æœ‰å•é¡Œ)

---
```

### Task 2.9: AI Selection (Gemini)

**æª”æ¡ˆ**: `docs/implementation-plan/phase-2-engines/task-2.9-ai-selection.md`

**æ’å…¥ä½ç½®**: åœ¨ã€Œå¸¸è¦‹å•é¡Œã€ä¹‹å‰

**æ’å…¥å…§å®¹**:

```markdown
---

## ğŸ“Š Logging èˆ‡éŒ¯èª¤è™•ç†æ•´åˆ

> åƒè€ƒ: [LOGGING-STANDARDS.md](../LOGGING-STANDARDS.md)

### å¿…é ˆè¨˜éŒ„çš„äº‹ä»¶

#### åŸºç¤äº‹ä»¶
- [ ] `task_started` - ä»»å‹™é–‹å§‹
- [ ] `task_step_started` - ç‚ºæ¯å€‹é…éŸ³ç‰‡æ®µé¸ç‰‡
- [ ] `task_step_completed` - é¸ç‰‡å®Œæˆ
- [ ] `task_completed` - æ‰€æœ‰é¸ç‰‡å®Œæˆ
- [ ] `task_failed` - ä»»å‹™å¤±æ•—

#### AI å‘¼å«äº‹ä»¶ (æ¯å€‹é…éŸ³ç‰‡æ®µéƒ½è¦è¨˜éŒ„ä¸€æ¬¡)
- [ ] `ai_call_started` - Gemini é¸ç‰‡é–‹å§‹
- [ ] `ai_call_completed` - é¸ç‰‡æˆåŠŸ
- [ ] `ai_call_failed` - Gemini å¤±æ•—
- [ ] `ai_response_validation_failed` - Schema æˆ–åƒç…§é©—è­‰å¤±æ•—

### æ•´åˆç¨‹å¼ç¢¼ç¯„ä¾‹

```typescript
class AISelectionEngine {
  async selectClips(voiceoverSegments: any[], userId: string) {
    const taskLogger = createTaskLogger('ai_selection', userId)
    const executionId = taskLogger.getExecutionId()
    const validator = new DataFlowValidator(taskLogger.getLogger())

    try {
      await taskLogger.taskStarted(
        { segments_count: voiceoverSegments.length },
        ['query_candidates', ...voiceoverSegments.map((_, i) => `select_segment_${i}`)]
      )

      const selections = []
      let totalCost = 0

      // ç‚ºæ¯å€‹é…éŸ³ç‰‡æ®µé¸ç‰‡
      for (let i = 0; i < voiceoverSegments.length; i++) {
        const segment = voiceoverSegments[i]

        await taskLogger.stepStarted(i + 1, `select_segment_${i}`)

        // æŸ¥è©¢å€™é¸ç‰‡æ®µ
        const candidates = await this.queryCandidates(segment)

        if (candidates.length === 0) {
          await taskLogger.getLogger().error('data_flow_validation_failed', {
            validation_error: 'EmptyQueryResult',
            error_message: `No candidates for voice segment ${i}`,
            error_details: {
              voice_text: segment.text,
              keywords: segment.keywords
            }
          })
          throw new ValidationError(`No candidates for segment ${i}`)
        }

        // AI é¸ç‰‡
        const callId = uuid()
        const { response, cost } = await promptManager.executePrompt(
          'video-selection',
          'segment-select',
          {
            voiceText: segment.text,
            duration: segment.end - segment.start,
            keywords: segment.keywords,
            candidates: candidates.map(c => ({
              id: c.segment_id,
              description: c.description,
              duration: c.duration
            }))
          },
          { executionId, userId, callId }
        )

        // âœ… é©—è­‰ Schema
        await validator.validateAIResponse(
          callId,
          'segment_selection',  // åœ¨ schemas.ts ä¸­å·²å®šç¾©
          response
        )

        // âœ… é©—è­‰åƒç…§å®Œæ•´æ€§ (selectedSegmentId å¿…é ˆåœ¨å€™é¸åˆ—è¡¨ä¸­)
        const candidateIds = candidates.map(c => c.segment_id)
        await validator.validateReference(
          response.selectedSegmentId,
          candidateIds,
          { voiceSegmentIndex: i, voiceText: segment.text }
        )

        // âœ… é©—è­‰æ•¸å€¼ç¯„åœ (trimEnd <= segment.duration)
        const selectedSegment = candidates.find(c => c.segment_id === response.selectedSegmentId)
        await validator.validateRange(
          response.trimEnd,
          'trimEnd',
          response.trimStart,  // min
          selectedSegment.duration,  // max
          { selectedSegmentId: response.selectedSegmentId }
        )

        await taskLogger.stepCompleted(i + 1, `select_segment_${i}`, {
          selected_id: response.selectedSegmentId,
          trim: `${response.trimStart}-${response.trimEnd}`
        })

        selections.push(response)
        totalCost += cost
      }

      await taskLogger.taskCompleted(
        { selections_count: selections.length },
        totalCost
      )

      return selections

    } catch (error) {
      await taskLogger.taskFailed(`select_segment`, error)
      throw error  // âœ… Fail Fast
    }
  }
}
```

### å¿…é ˆé©—è­‰çš„è³‡æ–™

æ ¹æ“š `schemas.ts`:
- [x] `selectedSegmentId`: string (required)
- [x] `trimStart`: number >= 0
- [x] `trimEnd`: number >= trimStart

**é¡å¤–é©—è­‰**:
- [x] selectedSegmentId åœ¨å€™é¸åˆ—è¡¨ä¸­ (ä½¿ç”¨ `validateReference`)
- [x] trimEnd <= segment.duration (ä½¿ç”¨ `validateRange`)

### Fail Fast æª¢æŸ¥æ¸…å–®

- [x] âœ… å€™é¸ç‰‡æ®µç‚ºç©ºæ™‚ç«‹å³ throw error (ä¸å˜—è©¦æ”¾å¯¬æ¢ä»¶)
- [x] âœ… AI é¸äº†ä¸å­˜åœ¨çš„ç‰‡æ®µæ™‚ç«‹å³ throw error
- [x] âœ… trim ç¯„åœéŒ¯èª¤æ™‚ç«‹å³ throw error
- [x] âœ… è¨˜éŒ„å®Œæ•´çš„é¸ç‰‡ä¸Šä¸‹æ–‡ (å€™é¸åˆ—è¡¨ã€AI å›æ‡‰ã€éŒ¯èª¤)

---
```

**æäº¤è¨Šæ¯**:
```bash
git add docs/implementation-plan/phase-2-engines/task-2.{7,9}*.md
git commit -m "feat(docs): Task 2.7, 2.9 åŠ å…¥ Logging æ•´åˆ

- Task 2.7: Voiceover Split æ™‚é–“è»¸é©—è­‰
- Task 2.9: AI Selection åƒç…§å®Œæ•´æ€§é©—è­‰

æ ¹æ“š LOGGING-STANDARDS.md

ğŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude <noreply@anthropic.com>"
git push
```

---

## Prompt 4: Task 2.10 (Timeline) + Task 2.12 (Video Composition)

**è² è²¬äºº**: Claude Code #4

### Task 2.10: Timeline Generation

**æª”æ¡ˆ**: `docs/implementation-plan/phase-2-engines/task-2.10-timeline-generation.md`

**æ’å…¥ä½ç½®**: åœ¨ã€Œå¸¸è¦‹å•é¡Œã€ä¹‹å‰

**æ’å…¥å…§å®¹**:

```markdown
---

## ğŸ“Š Logging èˆ‡éŒ¯èª¤è™•ç†æ•´åˆ

> åƒè€ƒ: [LOGGING-STANDARDS.md](../LOGGING-STANDARDS.md)

### å¿…é ˆè¨˜éŒ„çš„äº‹ä»¶

#### åŸºç¤äº‹ä»¶
- [ ] `task_started` - ä»»å‹™é–‹å§‹
- [ ] `task_step_started` - ç”Ÿæˆæ™‚é–“è»¸
- [ ] `task_step_completed` - æ™‚é–“è»¸ç”Ÿæˆå®Œæˆ
- [ ] `task_completed` - ä»»å‹™å®Œæˆ
- [ ] `task_failed` - ä»»å‹™å¤±æ•—
- [ ] `data_flow_validation_failed` - æ™‚é–“è»¸çµæ§‹é©—è­‰å¤±æ•—

### æ•´åˆç¨‹å¼ç¢¼ç¯„ä¾‹

```typescript
class TimelineGenerationEngine {
  async generateTimeline(selections: any[], voiceoverId: string, userId: string) {
    const taskLogger = createTaskLogger('timeline_generation', userId)
    const executionId = taskLogger.getExecutionId()
    const validator = new DataFlowValidator(taskLogger.getLogger())

    try {
      const voiceover = await db.voiceovers.findOne({ voiceoverId })

      await taskLogger.taskStarted(
        { selections_count: selections.length },
        ['generate_timeline', 'validate_timeline', 'save_timeline']
      )

      // Step 1: ç”Ÿæˆæ™‚é–“è»¸ JSON
      await taskLogger.stepStarted(0, 'generate_timeline')

      const timeline = {
        timeline_id: uuid(),
        voiceover_url: voiceover.file_url,
        total_duration: voiceover.duration,
        segments: selections.map((sel, index) => ({
          index,
          start_time: voiceover.segments[index].start,
          end_time: voiceover.segments[index].end,
          video_segment_id: sel.selectedSegmentId,
          video_trim_start: sel.trimStart,
          video_trim_end: sel.trimEnd
        }))
      }

      await taskLogger.stepCompleted(0, 'generate_timeline', {
        segments_count: timeline.segments.length
      })

      // Step 2: é©—è­‰æ™‚é–“è»¸çµæ§‹ âœ… é—œéµé©—è­‰ï¼
      await taskLogger.stepStarted(1, 'validate_timeline')

      await validator.validateDataFlow(
        'ai_selection',
        'timeline_generator',
        'timeline',  // åœ¨ schemas.ts ä¸­å·²å®šç¾©
        timeline
      )

      // é¡å¤–é©—è­‰: æ™‚é–“è»¸ä¸€è‡´æ€§
      const errors = []
      for (let i = 0; i < timeline.segments.length; i++) {
        const seg = timeline.segments[i]

        // æª¢æŸ¥ start < end
        if (seg.start_time >= seg.end_time) {
          errors.push({
            segment_index: i,
            error: 'start_time >= end_time',
            data: seg
          })
        }

        // æª¢æŸ¥ video_trim_end <= segment.duration
        const videoSegment = await db.segments.findOne({ segment_id: seg.video_segment_id })
        if (seg.video_trim_end > videoSegment.duration) {
          errors.push({
            segment_index: i,
            error: 'video_trim_end > segment.duration',
            data: { ...seg, segment_duration: videoSegment.duration }
          })
        }
      }

      if (errors.length > 0) {
        await taskLogger.getLogger().error('data_flow_validation_failed', {
          validation_error: 'InvalidTimelineStructure',
          error_message: 'Timeline has invalid time ranges',
          error_details: { validation_errors: errors }
        })
        throw new ValidationError(`Timeline validation failed: ${errors.length} errors`)
      }

      await taskLogger.stepCompleted(1, 'validate_timeline')

      // Step 3: å„²å­˜æ™‚é–“è»¸
      await taskLogger.stepStarted(2, 'save_timeline')
      await db.timelines.create({ timeline_json: timeline })
      await taskLogger.stepCompleted(2, 'save_timeline')

      await taskLogger.taskCompleted({ timeline_id: timeline.timeline_id }, 0)

      return timeline

    } catch (error) {
      await taskLogger.taskFailed('generate_timeline', error)
      throw error  // âœ… Fail Fast
    }
  }
}
```

### å¿…é ˆé©—è­‰çš„è³‡æ–™

æ ¹æ“š `schemas.ts`:
- [x] `timeline_id`: string
- [x] `voiceover_url`: string (uri)
- [x] `total_duration`: number >= 0
- [x] `segments`: array (min 1)
- [x] æ¯å€‹ segment çš„ start_time < end_time

**é¡å¤–é©—è­‰**:
- [x] video_trim_end <= segment.duration
- [x] æ‰€æœ‰ video_segment_id åœ¨è³‡æ–™åº«ä¸­å­˜åœ¨

### Fail Fast æª¢æŸ¥æ¸…å–®

- [x] âœ… æ™‚é–“ç¯„åœéŒ¯èª¤æ™‚ç«‹å³ throw error
- [x] âœ… ç‰‡æ®µä¸å­˜åœ¨æ™‚ç«‹å³ throw error
- [x] âœ… è¨˜éŒ„è©³ç´°çš„é©—è­‰éŒ¯èª¤

---
```

### Task 2.12: Video Composition

**æª”æ¡ˆ**: `docs/implementation-plan/phase-2-engines/task-2.12-video-composition.md`

**æ’å…¥ä½ç½®**: åœ¨ã€Œå¸¸è¦‹å•é¡Œã€ä¹‹å‰

**æ’å…¥å…§å®¹**:

```markdown
---

## ğŸ“Š Logging èˆ‡éŒ¯èª¤è™•ç†æ•´åˆ

> åƒè€ƒ: [LOGGING-STANDARDS.md](../LOGGING-STANDARDS.md)

### å¿…é ˆè¨˜éŒ„çš„äº‹ä»¶

#### åŸºç¤äº‹ä»¶
- [ ] `task_started` - ä»»å‹™é–‹å§‹
- [ ] `task_step_started` - ä¸‹è¼‰ç´ æ/åŸ·è¡Œ FFmpeg
- [ ] `task_step_completed` - æ­¥é©Ÿå®Œæˆ
- [ ] `task_completed` - å½±ç‰‡åˆæˆå®Œæˆ
- [ ] `task_failed` - ä»»å‹™å¤±æ•—

#### æª”æ¡ˆ/FFmpeg äº‹ä»¶
- [ ] `file_operation_failed` - æª”æ¡ˆä¸‹è¼‰å¤±æ•—
- [ ] `data_flow_validation_failed` - æª”æ¡ˆé©—è­‰å¤±æ•— (ä¸å­˜åœ¨/å¤§å°ç‚º0)
- [ ] `ffmpeg_execution_failed` - FFmpeg åŸ·è¡Œå¤±æ•—

### æ•´åˆç¨‹å¼ç¢¼ç¯„ä¾‹

```typescript
class VideoCompositionEngine {
  async compose(timelineId: string, userId: string) {
    const taskLogger = createTaskLogger('video_composition', userId)
    const executionId = taskLogger.getExecutionId()
    const validator = new DataFlowValidator(taskLogger.getLogger())

    try {
      const timeline = await db.timelines.findOne({ timelineId })

      await taskLogger.taskStarted(
        { timeline_id: timelineId, segments_count: timeline.timeline_json.segments.length },
        ['download_segments', 'validate_files', 'ffmpeg_compose', 'upload_result']
      )

      // Step 1: ä¸‹è¼‰ç´ æ
      await taskLogger.stepStarted(0, 'download_segments')

      const localFiles = []
      for (const seg of timeline.timeline_json.segments) {
        const segment = await db.segments.findOne({ segment_id: seg.video_segment_id })

        try {
          const localPath = await this.downloadFile(segment.file_path)
          localFiles.push({ segmentId: seg.video_segment_id, path: localPath })
        } catch (error) {
          await taskLogger.getLogger().error('file_operation_failed', {
            operation: 'download',
            file_path: segment.file_path,
            segment_id: seg.video_segment_id,
            error_type: error.constructor.name,
            error_message: error.message
          })
          throw error
        }
      }

      await taskLogger.stepCompleted(0, 'download_segments', {
        files_downloaded: localFiles.length
      })

      // Step 2: é©—è­‰æª”æ¡ˆ âœ… é—œéµé©—è­‰ï¼
      await taskLogger.stepStarted(1, 'validate_files')

      for (const file of localFiles) {
        await validator.validateFile(file.path, {
          mustExist: true,
          minSize: 1024  // è‡³å°‘ 1KB
        })
      }

      await taskLogger.stepCompleted(1, 'validate_files')

      // Step 3: FFmpeg åˆæˆ
      await taskLogger.stepStarted(2, 'ffmpeg_compose')

      const ffmpegCommand = this.buildFFmpegCommand(localFiles, timeline)
      const startTime = Date.now()

      try {
        const result = await this.executeFFmpeg(ffmpegCommand)
        const duration = Date.now() - startTime

        await taskLogger.stepCompleted(2, 'ffmpeg_compose', {
          duration_ms: duration,
          output_size: result.fileSize
        })

      } catch (error) {
        await taskLogger.getLogger().error('ffmpeg_execution_failed', {
          error_message: error.message,
          error_details: {
            exitCode: error.exitCode,
            // âœ… è¨˜éŒ„å®Œæ•´çš„ stderr (è¶…ç´šé‡è¦ï¼)
            stderr: error.stderr,
            // âœ… è¨˜éŒ„ FFmpeg æŒ‡ä»¤ (ç”¨æ–¼é‡ç¾å•é¡Œ)
            command: ffmpegCommand,
            // âœ… è¨˜éŒ„æ‰€æœ‰è¼¸å…¥æª”æ¡ˆè³‡è¨Š
            input_files: localFiles.map(f => ({
              path: f.path,
              size: fs.statSync(f.path).size,
              exists: fs.existsSync(f.path)
            }))
          }
        })
        throw error
      }

      // Step 4: ä¸Šå‚³çµæœ
      await taskLogger.stepStarted(3, 'upload_result')
      const outputUrl = await this.uploadToStorage(result.outputPath)
      await taskLogger.stepCompleted(3, 'upload_result')

      // è¨ˆç®—æˆæœ¬ (Cloudflare Stream)
      const cost = (timeline.timeline_json.total_duration / 45) * 0.004

      await taskLogger.taskCompleted({ output_url: outputUrl }, cost)

      return { url: outputUrl }

    } catch (error) {
      await taskLogger.taskFailed('ffmpeg_compose', error, {
        timeline_id: timelineId
      })
      throw error  // âœ… Fail Fast
    }
  }
}
```

### å¿…é ˆé©—è­‰çš„è³‡æ–™

- [x] æ‰€æœ‰ç‰‡æ®µæª”æ¡ˆå­˜åœ¨
- [x] æª”æ¡ˆå¤§å° > 0 bytes
- [x] FFmpeg åŸ·è¡ŒæˆåŠŸ (exit code 0)

### Fail Fast æª¢æŸ¥æ¸…å–®

- [x] âœ… æª”æ¡ˆä¸å­˜åœ¨æ™‚ç«‹å³ throw error
- [x] âœ… æª”æ¡ˆå¤§å°ç‚º 0 æ™‚ç«‹å³ throw error
- [x] âœ… FFmpeg å¤±æ•—æ™‚ç«‹å³ throw error (è¨˜éŒ„å®Œæ•´ stderr èˆ‡æŒ‡ä»¤)
- [x] âŒ ä¸å˜—è©¦ä¿®å¾©æˆ–é‡æ–°å˜—è©¦ (ç›´æ¥å¤±æ•—)

---
```

**æäº¤è¨Šæ¯**:
```bash
git add docs/implementation-plan/phase-2-engines/task-2.{10,12}*.md
git commit -m "feat(docs): Task 2.10, 2.12 åŠ å…¥ Logging æ•´åˆ

- Task 2.10: Timeline æ™‚é–“è»¸çµæ§‹é©—è­‰
- Task 2.12: Video Composition æª”æ¡ˆé©—è­‰èˆ‡ FFmpeg éŒ¯èª¤è¨˜éŒ„

æ ¹æ“š LOGGING-STANDARDS.md

ğŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude <noreply@anthropic.com>"
git push
```

---

## ğŸ“‹ å·¥ä½œåˆ†é…ç¸½çµ

| Claude Code | Tasks | é ä¼°æ™‚é–“ |
|-------------|-------|----------|
| #1 | Task 2.2, 2.3 | 15-20 åˆ†é˜ |
| #2 | Task 2.5, 2.6 | 15-20 åˆ†é˜ |
| #3 | Task 2.7, 2.9 | 20-25 åˆ†é˜ |
| #4 | Task 2.10, 2.12 | 20-25 åˆ†é˜ |

**ç¸½è¨ˆ**: 4 å€‹ Claude Code å¹³è¡Œä½œæ¥­,ç´„ 25 åˆ†é˜å…§å®Œæˆæ ¸å¿ƒ 8 å€‹ Tasks

---

## âœ… å®Œæˆå¾Œçš„é©—è­‰

æ‰€æœ‰ Claude Code å®Œæˆå¾Œ,åŸ·è¡Œ:

```bash
# æª¢æŸ¥æ‰€æœ‰æ›´æ–°çš„æª”æ¡ˆ
git log --oneline -10

# ç¢ºèª 8 å€‹æ ¸å¿ƒ Task éƒ½å·²æ›´æ–°
ls -la docs/implementation-plan/phase-2-engines/task-2.{2,3,5,6,7,9,10,12}*.md
```

---

## ğŸ“ æ³¨æ„äº‹é …

1. **æ’å…¥ä½ç½®**: çµ±ä¸€åœ¨ã€Œå¸¸è¦‹å•é¡Œã€æˆ–ã€ŒTask å®Œæˆç¢ºèªã€ä¹‹å‰
2. **æäº¤è¨Šæ¯**: ä½¿ç”¨çµ±ä¸€æ ¼å¼,åŒ…å« Claude Code æ¨™è¨˜
3. **ä¸è¦ä¿®æ”¹**: ç¾æœ‰çš„å¯¦ä½œæ­¥é©Ÿæˆ–å…¶ä»–ç« ç¯€
4. **é©—è­‰**: æ’å…¥å¾Œç¢ºèª Markdown æ ¼å¼æ­£ç¢º (ç„¡èªæ³•éŒ¯èª¤)

---

**æº–å‚™å¥½äº†å—?** è¤‡è£½ä»¥ä¸Š 4 å€‹ Prompt çµ¦ 4 å€‹ Claude Code,è®“å®ƒå€‘å¹³è¡Œä½œæ¥­ï¼
